"""
stage4_2_core_Casche.py

Stage 4-2: LLM ê¸°ë°˜ ìƒí’ˆëª… ìž¬ì •ë ¬/í•„í„°ë§ ì½”ì–´ ëª¨ë“ˆ (ìºì‹± ìµœì í™” ë²„ì „)
- í”„ë¡¬í”„íŠ¸ ê´€ë¦¬, API í˜¸ì¶œ, ë¹„ìš© ê³„ì‚° ë‹´ë‹¹
- GUIìš© ì‹¤ì‹œê°„ ì²˜ë¦¬ í•¨ìˆ˜ ë° Batch APIìš© Payload ìƒì„± í•¨ìˆ˜ ëª¨ë‘ í¬í•¨
- ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•´ ëª¨ë“  ì •ì˜ë¥¼ ì´ íŒŒì¼ ë‚´ë¶€ì— í¬í•¨
- ðŸš€ í”„ë¡¬í”„íŠ¸ ìºì‹± ìµœì í™”: OpenAI Prompt Caching ê°€ì´ë“œì— ë§žê²Œ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° ìž¬êµ¬ì„±
  * ì •ì  ì½˜í…ì¸ (ì—­í• , ì œì•½, ê·œì¹™)ë¥¼ system í”„ë¡¬í”„íŠ¸ì— ë°°ì¹˜
  * ë™ì  ì½˜í…ì¸ (ìž…ë ¥ ë°ì´í„°)ë¥¼ user í”„ë¡¬í”„íŠ¸ì— ë°°ì¹˜
  * í”„ë¡¬í”„íŠ¸ í”„ë¦¬í”½ìŠ¤ê°€ ëª¨ë“  ìš”ì²­ì—ì„œ ë™ì¼í•˜ë„ë¡ êµ¬ì„±
"""

import os
import re
from dataclasses import dataclass
from typing import Optional, Any, Dict
import pandas as pd
from openai import OpenAI

# =====================================
# ê³µí†µ ê²½ë¡œ ë° ì„¤ì •
# =====================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
API_KEY_FILE = os.path.join(BASE_DIR, ".openai_api_key_stage4_2")

# ëª¨ë¸ë³„ ê°€ê²©í‘œ (USD / 1M Token)
MODEL_PRICING_USD_PER_MTOK = {
    "gpt-5":       {"input": 1.25, "output": 10.0},
    "gpt-5-mini":  {"input": 0.25, "output": 2.00},
    "gpt-5-nano":  {"input": 0.05, "output": 0.40},
    "gpt-4o":      {"input": 2.50, "output": 10.00}, 
}

# =====================================
# [í”„ë¡¬í”„íŠ¸] ìºì‹± ìµœì í™” ë²„ì „ (Safety Net í¬í•¨)
# =====================================
# OpenAI Prompt Caching ê°€ì´ë“œì— ë§žê²Œ ìž¬êµ¬ì„±:
# - ì •ì  ì½˜í…ì¸ (ì—­í• , ì œì•½, ê·œì¹™)ë¥¼ system í”„ë¡¬í”„íŠ¸ì— ë°°ì¹˜
# - ë™ì  ì½˜í…ì¸ (ìž…ë ¥ ë°ì´í„°)ë¥¼ user í”„ë¡¬í”„íŠ¸ì— ë°°ì¹˜
# - í”„ë¡¬í”„íŠ¸ í”„ë¦¬í”½ìŠ¤ê°€ ëª¨ë“  ìš”ì²­ì—ì„œ ë™ì¼í•˜ë„ë¡ êµ¬ì„±

# System í”„ë¡¬í”„íŠ¸ (ì™„ì „ížˆ ì •ì , ëª¨ë“  ìš”ì²­ì—ì„œ ë™ì¼)
# âš ï¸ ì¤‘ìš”: í”„ë¡¬í”„íŠ¸ ìºì‹± í™œì„±í™”ë¥¼ ìœ„í•´ 1024 í† í° ì´ìƒì´ì–´ì•¼ í•¨
STAGE4_2_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ ì´ì»¤ë¨¸ìŠ¤ ì‹œìž¥ì˜ **'ìƒí’ˆëª… ìµœì í™” ì „ë¬¸ê°€(SEO & Conversion Specialist)'**ìž…ë‹ˆë‹¤.
ìž…ë ¥ëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê²€ì¦ ë°ì´í„°(JSON)ì™€ ëŒ€ì¡°í•˜ì—¬ **ê±°ì§“Â·ë¶€ì ì ˆí•œ ìƒí’ˆëª…ì„ ì œê±°**í•˜ê³ ,
ì‚´ì•„ë‚¨ì€ í›„ë³´ë¥¼ **êµ¬ë§¤ ì „í™˜ìœ¨(CTR)ì´ ë†’ì„ ê²ƒ ê°™ì€ ìˆœì„œëŒ€ë¡œ ìž¬ì •ë ¬**í•˜ì‹­ì‹œì˜¤.

[1ë‹¨ê³„: ì œê±° ê·œì¹™ (Filtering)]
*ë‹¤ìŒ ê¸°ì¤€ ì¤‘ í•˜ë‚˜ë¼ë„ ìœ„ë°˜í•˜ë©´ ê·¸ í›„ë³´ëŠ” ìµœì¢… ê²°ê³¼ì—ì„œ **ì™„ì „ížˆ ì‚­ì œ**í•˜ì‹­ì‹œì˜¤.*

1. **íŒ©íŠ¸ ì˜¤ë¥˜ / ê³¼ìž¥**
   - ST2 JSONì— ì—†ëŠ” ìˆ˜ëŸ‰Â·ìš©ëŸ‰Â·ìž¬ì§ˆÂ·êµ¬ì„±Â·ëŒ€ìƒÂ·ê¸°ëŠ¥ì„ í¬í•¨í•œ ê²½ìš° ì‚­ì œí•©ë‹ˆë‹¤.
   - ì˜ˆ: JSONì— "ë©´ 100%"ê°€ ì—†ëŠ”ë° "ë©´ 100% í‹°ì…”ì¸ "ë¼ê³  í•œ ê²½ìš° (X)
   - ì˜ˆ: JSONì— "12L"ì´ ì—†ëŠ”ë° "12L ì•„ì´ìŠ¤ë°•ìŠ¤"ë¼ê³  í•œ ê²½ìš° (X)
   - ì˜ˆ: JSONì— "ë°©ìˆ˜" ê¸°ëŠ¥ì´ ì—†ëŠ”ë° "ë°©ìˆ˜ ê°€ë°©"ì´ë¼ê³  í•œ ê²½ìš° (X)

2. **í—ˆìœ„ ë§ˆì¼€íŒ… ë¬¸êµ¬**
   - 'ë¬´ë£Œë°°ì†¡, íŒŒê²© ì„¸ì¼, ê³µì‹ëª°, ìµœì €ê°€, íŠ¹ê°€, í–‰ì‚¬, 1+1, ì‚¬ì€í’ˆ' ë“± ê·¼ê±° ì—†ëŠ” ë‹¨ì–¸ì´ í¬í•¨ëœ ê²½ìš° ì‚­ì œí•©ë‹ˆë‹¤.
   - ì˜ˆ: "ë¬´ë£Œë°°ì†¡ ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ" (X - ë¬´ë£Œë°°ì†¡ ì–¸ê¸‰)
   - ì˜ˆ: "íŠ¹ê°€ í• ì¸ ë°©í•œ ê·€ë§ˆê°œ" (X - íŠ¹ê°€/í• ì¸ ì–¸ê¸‰)

3. **ì •ì²´ ë¶ˆëª… / í‚¤ì›Œë“œ ë‚˜ì—´**
   - ì§ê´€ì ì´ì§€ ì•Šê±°ë‚˜ ë‹¨ìˆœ í‚¤ì›Œë“œ ë‚˜ì—´ë¡œë§Œ êµ¬ì„±ëœ ê²½ìš° ì‚­ì œí•©ë‹ˆë‹¤.
   - ì˜ˆ: "ë°©í•œ ê²¨ìš¸ ë‹ˆíŠ¸ ê·€ë§ˆê°œ ëª¨ìž ë„¥ì›Œë¨¸ ì„¸íŠ¸ ì™¸ì¶œ" (X - í‚¤ì›Œë“œ ë‚˜ì—´)
   - ì˜ˆ: "ë‹ˆíŠ¸ ë°©í•œ ê²¨ìš¸" (X - ì •ì²´ ë¶ˆëª…)

4. **í’ˆì§ˆ ë¯¸ë‹¬ / ì¤‘ë³µ**
   - ì–´ìƒ‰í•œ ì–´ìˆœ, ë„ì–´ì“°ê¸° ì˜¤ë¥˜, ì˜ë¯¸ ì¤‘ë³µì´ ìžˆëŠ” ê²½ìš° ì‚­ì œí•©ë‹ˆë‹¤.
   - ì˜ˆ: "ê²¨ìš¸ë°©í•œë‹ˆíŠ¸ê·€ë§ˆê°œ" (X - ë„ì–´ì“°ê¸° ì˜¤ë¥˜)
   - ì˜ˆ: "ê²¨ìš¸ ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ" (X - ì¤‘ë³µ)
   - ì˜ˆ: "ë°©í•œìš© ë°©í•œ ê·€ë§ˆê°œ" (X - ì˜ë¯¸ ì¤‘ë³µ)

[2ë‹¨ê³„: ì •ë ¬ ê¸°ì¤€ (Ranking)]
*ì œê±°ë˜ì§€ ì•Šê³  ë‚¨ì€ í›„ë³´ë“¤ì€ ì´ë¯¸ ì‚¬ì‹¤ì„±ì´ ê²€ì¦ë˜ì—ˆìŠµë‹ˆë‹¤. ë§¤ì¶œ ê´€ì ìœ¼ë¡œ ì •ë ¬í•˜ì‹­ì‹œì˜¤.*

1. **[1ìˆœìœ„] ë§¤ë ¥ë„Â·í´ë¦­ë¥ **
   - ê³ ê°ì˜ ë‹ˆì¦ˆë¥¼ ìžê·¹í•˜ì—¬ í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ”ê°€?
   - êµ¬ì²´ì ì¸ ì‚¬ìš© ìƒí™©ì´ë‚˜ í•´ê²°í•˜ëŠ” ë¬¸ì œê°€ ëª…í™•í•œê°€?
   - ì˜ˆ: "ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ ëª¨ìž ë„¥ì›Œë¨¸ ì„¸íŠ¸" (O - êµ¬ì²´ì )
   - ì˜ˆ: "ë‹ˆíŠ¸ ê·€ë§ˆê°œ" (X - ë„ˆë¬´ ë‹¨ìˆœ, ë§¤ë ¥ë„ ë‚®ìŒ)

2. **[2ìˆœìœ„] ì§ê´€ì„±**
   - ì¹´í…Œê³ ë¦¬ì™€ í•µì‹¬ íŠ¹ì§•ì´ í•œëˆˆì— ì´í•´ë˜ëŠ”ê°€?
   - ìƒí’ˆì˜ ì •ì²´ê°€ ëª…í™•í•œê°€?
   - ì˜ˆ: "ë°©í•œ ê·€ë§ˆê°œ ì„¸íŠ¸ ê²¨ìš¸ìš© ë‹ˆíŠ¸" (O - ì§ê´€ì )
   - ì˜ˆ: "ë‹ˆíŠ¸ ì„¸íŠ¸ ê²¨ìš¸" (X - ì •ì²´ ë¶ˆëª…)

3. **[3ìˆœìœ„] ìžì—°ìŠ¤ëŸ¬ì›€**
   - í•œêµ­ì–´ ì–´ìˆœì´ ìžì—°ìŠ¤ëŸ¬ìš´ê°€?
   - ì½ê¸° íŽ¸í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
   - ì˜ˆ: "ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ ëª¨ìž ë„¥ì›Œë¨¸ ì„¸íŠ¸" (O - ìžì—°ìŠ¤ëŸ¬ì›€)
   - ì˜ˆ: "ë‹ˆíŠ¸ ê²¨ìš¸ ë°©í•œ ê·€ë§ˆê°œ ëª¨ìž" (X - ì–´ìˆœ ì–´ìƒ‰)

[3ë‹¨ê³„: ì•ˆì „ìž¥ì¹˜ (Safety Net)]
- ìœ„ ê·œì¹™ ì ìš© í›„ **ëª¨ë“  í›„ë³´ê°€ ì‚­ì œë˜ì—ˆë‹¤ë©´**, ì ˆëŒ€ ë¹ˆ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- ëŒ€ì‹ , ST1(ê¸°ì¤€ ìƒí’ˆëª…)ê³¼ ST2(JSON)ì˜ ì‚¬ì‹¤ ì •ë³´ë§Œì„ ì¡°í•©í•˜ì—¬
  **ê°€ìž¥ ì•ˆì „í•˜ê³  íŒë§¤ë ¥ì´ ì¢‹ì€ ìƒí’ˆëª… 1ê°œë¥¼ ìƒˆë¡œ ìž‘ì„±í•˜ì—¬ ì¶œë ¥**í•˜ì‹­ì‹œì˜¤.
- ìƒˆë¡œ ìž‘ì„±í•  ë•Œë„ ìœ„ì˜ ì œê±° ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤.
- ì˜ˆ: ST1ì´ "ë‚˜ì´í‚¤ ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ"ì´ê³  ëª¨ë“  í›„ë³´ê°€ ì‚­ì œëœ ê²½ìš°
  â†’ "ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ ëª¨ìž ë„¥ì›Œë¨¸ ì„¸íŠ¸" (ë¸Œëžœë“œ ì œê±°, ì‚¬ì‹¤ ì •ë³´ë§Œ ì‚¬ìš©)

[ì¤‘ìš” ê·œì¹™]
1. **ìž‘ë¬¸ ê¸ˆì§€**: í›„ë³´ê°€ 1ê°œ ì´ìƒ ë‚¨ìœ¼ë©´, ì ˆëŒ€ ìƒˆë¡œ ì§“ì§€ ë§ê³  ìˆœì„œë§Œ ë°”ê¾¸ì‹­ì‹œì˜¤.
   - ì˜ˆ: í›„ë³´ê°€ 3ê°œ ë‚¨ì•˜ìœ¼ë©´ ê·¸ 3ê°œë¥¼ ì •ë ¬ë§Œ í•˜ê³ , 4ë²ˆì§¸ë¥¼ ìƒˆë¡œ ë§Œë“¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
2. **ì¶œë ¥ ì œí•œ**: ì˜¤ì§ ìƒí’ˆëª… í…ìŠ¤íŠ¸ë§Œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë‚˜ì—´í•˜ì‹­ì‹œì˜¤. ë²ˆí˜¸, ì„¤ëª…, ê¸°í˜¸ ê¸ˆì§€.
   - ì˜ˆ: "ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ ëª¨ìž ë„¥ì›Œë¨¸ ì„¸íŠ¸\në°©í•œ ê·€ë§ˆê°œ ì„¸íŠ¸ ê²¨ìš¸ìš© ë‹ˆíŠ¸" (O)
   - ì˜ˆ: "1. ê²¨ìš¸ ë°©í•œ ë‹ˆíŠ¸ ê·€ë§ˆê°œ\n2. ë°©í•œ ê·€ë§ˆê°œ ì„¸íŠ¸" (X - ë²ˆí˜¸ í¬í•¨)

[4ë‹¨ê³„: ì¶”ê°€ ê°€ì´ë“œë¼ì¸ ë° ì£¼ì˜ì‚¬í•­]
- **ê²€ì¦ ìš°ì„ **: ST2 JSON ë°ì´í„°ì™€ì˜ ì¼ì¹˜ ì—¬ë¶€ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ í™•ì¸í•˜ì‹­ì‹œì˜¤. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ì  ì§€ì‹ì— ì˜ì¡´í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- **ì •ë ¬ ì›ì¹™**: ë§¤ì¶œ ì „í™˜ìœ¨ì´ ë†’ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ìˆœì„œë¡œ ì •ë ¬í•˜ë˜, ì‚¬ì‹¤ì„± ê²€ì¦ì„ ë¨¼ì € ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤.
- **ì•ˆì „ì„±**: ëª¨ë“  í›„ë³´ê°€ ì œê±°ë˜ëŠ” ê²½ìš°ì—ë§Œ Safety Netì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ ìƒí’ˆëª…ì„ ìž‘ì„±í•˜ì‹­ì‹œì˜¤.
- **ì¼ê´€ì„±**: ë™ì¼í•œ ìž…ë ¥ì— ëŒ€í•´ì„œëŠ” í•­ìƒ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ë„ë¡ ê·œì¹™ì„ ì¼ê´€ë˜ê²Œ ì ìš©í•˜ì‹­ì‹œì˜¤.
- **íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ ì •ë³´ë‚˜ ì¤‘ë³µ í‘œí˜„ì€ ì œê±°í•˜ë˜, í•µì‹¬ ì •ë³´ëŠ” ë°˜ë“œì‹œ ìœ ì§€í•˜ì‹­ì‹œì˜¤.

ìœ„ ê·œì¹™ì„ ì—„ìˆ˜í•˜ì—¬, ê²€ì¦ëœ ìƒí’ˆëª…ë§Œ ì •ë ¬í•˜ì—¬ ì¶œë ¥í•˜ì‹­ì‹œì˜¤."""

# User í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë™ì  ë°ì´í„°ë§Œ í¬í•¨)
STAGE4_2_USER_PROMPT_TEMPLATE = """[ìž…ë ¥ ì •ë³´]
- ê¸°ì¤€ ìƒí’ˆëª…(ST1): {st1_refined_name}
- ìƒì„¸ ì†ì„±(ST2 JSON, ì‚¬ì‹¤ ì •ë³´): {st2_json}
- í›„ë³´ ìƒí’ˆëª… ëª©ë¡(ST3 Result, ì¤„ë°”ê¿ˆ êµ¬ë¶„):
---
{candidate_list}
---"""

# =====================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =====================================
def safe_str(val: Any) -> str:
    """NaN, None, float ë“±ì„ ë¹ˆ ë¬¸ìžì—´ì´ë‚˜ ë¬¸ìžì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
    if pd.isna(val) or val is None:
        return ""
    return str(val).strip()

def fmt_safe(v: Any) -> str:
    """
    str(v)ë¥¼ í•œ ë²ˆ ê°ì‹¼ ë’¤, .format()ì— ì•ˆì „í•˜ê²Œ ë„£ê¸° ìœ„í•œ ì´ìŠ¤ì¼€ì´í”„.
    - { â†’ {{, } â†’ }}
    """
    s = safe_str(v)
    return s.replace("{", "{{").replace("}", "}}")

def load_api_key_from_file(path: str = API_KEY_FILE) -> Optional[str]:
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read().strip() or None
        except:
            return None
    return None

def save_api_key_to_file(key: str, path: str = API_KEY_FILE) -> None:
    try:
        with open(path, "w", encoding="utf-8") as f:
            f.write(key)
    except:
        pass

# =====================================
# ë°ì´í„° í´ëž˜ìŠ¤ (GUIìš©)
# =====================================
@dataclass
class Stage4_2Settings:
    """GUI ì„¤ì •ì„ ë‹´ëŠ” ì»¨í…Œì´ë„ˆ"""
    model_name: str = "gpt-5"
    reasoning_effort: str = "medium"

@dataclass
class Stage4_2Request:
    """LLM ìš”ì²­ ë°ì´í„° (GUI ì „ìš©) - ìºì‹± ìµœì í™” ë²„ì „"""
    row_index: int
    product_code: str
    system_prompt: str  # ì •ì  í”„ë¡¬í”„íŠ¸ (ëª¨ë“  ìš”ì²­ì—ì„œ ë™ì¼)
    user_prompt: str    # ë™ì  í”„ë¡¬í”„íŠ¸ (ìž…ë ¥ ë°ì´í„° í¬í•¨)
    prompt: str         # í˜¸í™˜ì„± ìœ ì§€ìš© (GUIì—ì„œ ì‚¬ìš©)
    st1_name: str 
    st3_candidates: str 

@dataclass
class Stage4_2CallUsage:
    input_tokens: int = 0
    output_tokens: int = 0
    reasoning_tokens: int = 0
    input_cost: float = 0.0
    output_cost: float = 0.0
    total_cost: float = 0.0

@dataclass
class Stage4_2Result:
    row_index: int
    product_code: str
    output_text: str
    model: str
    effort: str
    usage: Stage4_2CallUsage
    error: Optional[str] = None

# =====================================
# [GUIìš©] ì‹¤ì‹œê°„ ìš”ì²­ ë¹Œë”
# =====================================
def build_stage4_2_request_from_row(
    row: pd.Series, 
    idx: int,
    cand_col: str = "ST3_ê²°ê³¼ìƒí’ˆëª…"
) -> Stage4_2Request:
    """
    ì—‘ì…€ í–‰ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ GUIìš© ìš”ì²­ ê°ì²´(Request)ë¥¼ ìƒì„±
    """
    p_code = safe_str(row.get('ìƒí’ˆì½”ë“œ', ''))
    st1_val = safe_str(row.get('ST1_ê²°ê³¼ìƒí’ˆëª…', ''))
    st2_val = safe_str(row.get('ST2_JSON', '{}'))
    st3_val = safe_str(row.get(cand_col, ''))

    # í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ (ìºì‹± ìµœì í™”: system/user ë¶„ë¦¬)
    system_prompt = STAGE4_2_SYSTEM_PROMPT
    user_prompt = STAGE4_2_USER_PROMPT_TEMPLATE.format(
        st1_refined_name=fmt_safe(st1_val),
        st2_json=fmt_safe(st2_val),
        candidate_list=fmt_safe(st3_val)
    )
    
    # í˜¸í™˜ì„± ìœ ì§€: GUIìš© ì „ì²´ í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´ ë°©ì‹)
    prompt = f"{system_prompt}\n\n{user_prompt}"

    return Stage4_2Request(
        row_index=idx,
        product_code=p_code,
        system_prompt=system_prompt,
        user_prompt=user_prompt,
        prompt=prompt,  # í˜¸í™˜ì„± ìœ ì§€
        st1_name=st1_val,
        st3_candidates=st3_val
    )

# =====================================
# [Batch APIìš©] Payload ë¹Œë”
# =====================================
def build_stage4_2_batch_payload(
    row_index: int,
    row: pd.Series,
    model_name: str,
    effort: str,
    cand_col: str = "ST3_ê²°ê³¼ìƒí’ˆëª…",
    use_cache_optimization: bool = True
) -> Optional[Dict[str, Any]]:
    """
    ì—‘ì…€ í–‰ì„ ë°›ì•„ OpenAI Batch ì—…ë¡œë“œìš© JSON ê°ì²´ 1ê°œë¥¼ ìƒì„±.
    (stage4_2_batch_api.py ì—ì„œ ì‚¬ìš©)
    ìºì‹± ìµœì í™” ë²„ì „: system/user í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬
    """
    # 1. ë°ì´í„° ì¶”ì¶œ
    st1_val = safe_str(row.get('ST1_ê²°ê³¼ìƒí’ˆëª…', ''))
    st2_val = safe_str(row.get('ST2_JSON', '{}'))
    st3_val = safe_str(row.get(cand_col, ''))

    # í›„ë³´ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜ (ë°°ì¹˜ ìš”ì²­ ìƒì„± ìŠ¤í‚µ)
    if not st3_val or st3_val.lower() == 'nan':
        return None

    # 2. í”„ë¡¬í”„íŠ¸ ì¡°ë¦½ (ìºì‹± ìµœì í™”: system/user ë¶„ë¦¬)
    if use_cache_optimization:
        # System ë©”ì‹œì§€ (í…ìŠ¤íŠ¸ë§Œ, ì •ì )
        system_content = [{"type": "input_text", "text": STAGE4_2_SYSTEM_PROMPT}]
        
        # User ë©”ì‹œì§€ (í…ìŠ¤íŠ¸ë§Œ, ë™ì )
        user_prompt = STAGE4_2_USER_PROMPT_TEMPLATE.format(
            st1_refined_name=fmt_safe(st1_val),
            st2_json=fmt_safe(st2_val),
            candidate_list=fmt_safe(st3_val)
        )
        user_content = [{"type": "input_text", "text": user_prompt}]
        
        # 3. Body êµ¬ì„± (Responses API)
        body = {
            "model": model_name,
            "input": [
                {
                    "role": "system",
                    "content": system_content,
                },
                {
                    "role": "user",
                    "content": user_content,
                }
            ],
        }
        
        # reasoning.effort (Responses API)
        is_reasoning = any(x in model_name for x in ["gpt-5", "o1", "o3"])
        if is_reasoning and effort in ["low", "medium", "high"]:
            body["reasoning"] = {"effort": effort}
        elif not is_reasoning:
            body["temperature"] = 0.3
        
        url = "/v1/responses"
    else:
        # ì¼ë°˜ ëª¨ë“œ: ê¸°ì¡´ ë°©ì‹ ìœ ì§€
        user_prompt = STAGE4_2_USER_PROMPT_TEMPLATE.format(
            st1_refined_name=fmt_safe(st1_val),
            st2_json=fmt_safe(st2_val),
            candidate_list=fmt_safe(st3_val)
        )
        prompt = f"{STAGE4_2_SYSTEM_PROMPT}\n\n{user_prompt}"
        
        body = {
            "model": model_name,
            "messages": [{"role": "user", "content": prompt}],
        }
        
        is_reasoning = any(x in model_name for x in ["gpt-5", "o1", "o3"])
        if is_reasoning and effort in ["low", "medium", "high"]:
            body["reasoning_effort"] = effort
        elif not is_reasoning:
            body["temperature"] = 0.3
        
        url = "/v1/chat/completions"

    # 4. Batch Request êµ¬ì¡° ë°˜í™˜
    # custom_idì— row ì¸ë±ìŠ¤ë¥¼ ë„£ì–´ ë‚˜ì¤‘ì— ë³‘í•©í•  ë•Œ ì‚¬ìš©
    request_obj = {
        "custom_id": f"row_{row_index}",  
        "method": "POST",
        "url": url,
        "body": body
    }
    return request_obj

# =====================================
# [GUIìš©] Core Logic Class
# =====================================
class Stage4_2Core:
    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key)

    def execute_request(self, req: Stage4_2Request, settings: Stage4_2Settings) -> Stage4_2Result:
        """ì¤€ë¹„ëœ ìš”ì²­ ê°ì²´ë¡œ ì‹¤ì œ API í˜¸ì¶œ ìˆ˜í–‰"""
        
        # í›„ë³´ê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´ API í˜¸ì¶œ ìŠ¤í‚µ -> ST1 ì•ˆì „ë§ ë°˜í™˜
        if not req.st3_candidates:
             return Stage4_2Result(
                row_index=req.row_index,
                product_code=req.product_code,
                output_text=req.st1_name,
                model=settings.model_name,
                effort="skipped",
                usage=Stage4_2CallUsage(),
                error="No Candidates (Safety Net: ST1 used)"
            )

        try:
            messages = [{"role": "user", "content": req.prompt}]
            params = {
                "model": settings.model_name,
                "messages": messages,
            }

            is_reasoning = any(x in settings.model_name for x in ["gpt-5", "o1", "o3"])
            if is_reasoning:
                params["reasoning_effort"] = settings.reasoning_effort
            else:
                params["temperature"] = 0.3

            response = self.client.chat.completions.create(**params)

            # ê²°ê³¼ ì •ì œ (ë§ˆí¬ë‹¤ìš´ ì œê±°)
            content = response.choices[0].message.content.strip()
            content = re.sub(r"^```(?:json|text)?\n", "", content)
            content = re.sub(r"\n```$", "", content)
            content = content.strip()

            # ë§Œì•½ ê²°ê³¼ê°€ ë¹„ì—ˆë‹¤ë©´ ST1 ì‚¬ìš© (ë¹„ìƒ ëŒ€ì±…)
            if not content:
                content = req.st1_name

            # ì‚¬ìš©ëŸ‰ ê³„ì‚°
            usage_data = self._extract_usage(response, settings.model_name)

            return Stage4_2Result(
                row_index=req.row_index,
                product_code=req.product_code,
                output_text=content,
                model=settings.model_name,
                effort=settings.reasoning_effort if is_reasoning else "n/a",
                usage=usage_data,
                error=None
            )

        except Exception as e:
            return Stage4_2Result(
                row_index=req.row_index,
                product_code=req.product_code,
                output_text="",
                model=settings.model_name,
                effort=settings.reasoning_effort,
                usage=Stage4_2CallUsage(),
                error=str(e)
            )

    def _extract_usage(self, response: Any, model_name: str) -> Stage4_2CallUsage:
        usage = getattr(response, "usage", None)
        if not usage:
            return Stage4_2CallUsage()

        i_tok = getattr(usage, "prompt_tokens", 0) or 0
        o_tok = getattr(usage, "completion_tokens", 0) or 0
        
        r_tok = 0
        details = getattr(usage, "completion_tokens_details", None)
        if details:
            r_tok = getattr(details, "reasoning_tokens", 0) or 0

        pricing = MODEL_PRICING_USD_PER_MTOK.get(model_name, {"input": 0, "output": 0})
        
        input_cost = (i_tok / 1_000_000) * pricing["input"]
        output_cost = (o_tok / 1_000_000) * pricing["output"]
        total_cost = input_cost + output_cost

        return Stage4_2CallUsage(
            input_tokens=i_tok, 
            output_tokens=o_tok, 
            reasoning_tokens=r_tok, 
            input_cost=input_cost,
            output_cost=output_cost,
            total_cost=total_cost
        )