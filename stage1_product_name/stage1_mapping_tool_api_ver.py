import os
import re
import threading
import json
from typing import Optional, Tuple, Any

import pandas as pd
from openai import OpenAI

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from tkinter.scrolledtext import ScrolledText

# =========================
# ì „ì—­ ì„¤ì •
# =========================

client: Optional[OpenAI] = None
STOP_REQUESTED = False

# API í‚¤ ì €ì¥ íŒŒì¼ (ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”)
CONFIG_API_KEY_PATH = os.path.join(os.path.dirname(__file__), ".openai_api_key")

# ìµœì¢… ì¶œë ¥ í† í° ìƒí•œ (ì •ì œ ìƒí’ˆëª… í•œ ì¤„ì´ë©´ 128ì´ë©´ ì¶©ë¶„)
DEFAULT_MAX_OUTPUT_TOKENS = 128


def safe_str(v) -> str:
    """NaN/None ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜ + strip."""
    if v is None:
        return ""
    try:
        if pd.isna(v):
            return ""
    except Exception:
        pass
    return str(v).strip()


# =========================
# Stage1 ê³µí†µ SYSTEM í”„ë¡¬í”„íŠ¸
# =========================

STAGE1_SYSTEM_PROMPT = """ë„ˆëŠ” ì „ë¬¸ MDì´ì ì˜¨ë¼ì¸ ì‡¼í•‘ëª° *ìœ„íƒíŒë§¤*ìš© ìƒí’ˆëª… ì •ì œ ì „ë¬¸ê°€ë‹¤.  
ë„¤ ì„ë¬´ëŠ” ê³µê¸‰ì²˜ì—ì„œ ì˜¨ â€œì›ë³¸ ìƒí’ˆëª…â€ì„ ê¹”ë”í•˜ê³  ì •ë³´ ì¤‘ì‹¬ì˜ â€œì •ì œëœ ìƒí’ˆëª…â€ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê²ƒì´ë‹¤.

[ë©”íƒ€ ê·œì¹™ â€“ ë‚´ë¶€ ì ê²€]
1. ë‹µë³€ì„ ë§Œë“¤ê¸° ì „ì— ìŠ¤ìŠ¤ë¡œ ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ë¬¼ì„ ì ê²€í•œë‹¤.
   - ì •ë³´ ì •í™•ì„±: ì›ë³¸ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ê³ , ì¶”ì¸¡ ì •ë³´(ë¸Œëœë“œ/ìš©ëŸ‰/ì¬ì§ˆ/ê¸°ëŠ¥ ë“±)ë¥¼ ìƒˆë¡œ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤.
   - êµ¬ì¡°: ê°€ëŠ¥í•œ í•œ ë‹¤ìŒ ìˆœì„œë¥¼ ìš°ì„  ê³ ë ¤í•œë‹¤.  
     â†’ í•µì‹¬ ì œí’ˆêµ°/íƒ€ì… > í•µì‹¬ ê¸°ëŠ¥Â·íš¨ê³¼/ì‚¬ìš©ìƒí™© > ê·œê²©Â·ìš©ëŸ‰/ì„¸íŠ¸Â·ìˆ˜ëŸ‰ > ì‚¬ìš©ëŒ€ìƒÂ·ìŠ¤íƒ€ì¼/í• > ì‹œì¦ŒÂ·í…Œë§ˆ > ìƒ‰ìƒ/ì˜µì…˜(í•„ìš” ì‹œ)
   - ê°„ê²°ì„±: ìµœëŒ€ 60ì ì´ë‚´, ì˜ë¯¸ ì—†ëŠ” ìˆ˜ì‹ì–´Â·ì¤‘ë³µ ë‹¨ì–´Â·ê´‘ê³  ë¬¸êµ¬Â·ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°.
   - ì¼ê´€ì„±: ë™ì¼ ìœ í˜•ì˜ ì •ë³´ëŠ” ìœ ì‚¬í•œ í‘œí˜„ê³¼ ìˆœì„œë¥¼ ìœ ì§€í•œë‹¤(ì˜ˆ: â€œí¬ë¦¬ìŠ¤ë§ˆìŠ¤ íŒŒí‹° ê°€ëœë“œ ë ˆí„° ì‚°íƒ€ ì¥ì‹ ì†Œí’ˆâ€ì²˜ëŸ¼).
2. ìœ„ ê¸°ì¤€ì— ìŠ¤ìŠ¤ë¡œ â€œë§Œì â€ì´ë¼ íŒë‹¨ë  ë•Œê¹Œì§€ ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì—¬ëŸ¬ ë²ˆ ë‹¤ë“¬ì€ ë’¤,
   ì‚¬ìš©ìì—ê²ŒëŠ” ìµœì¢… ì™„ì„±ëœ í•œ ì¤„ë§Œ ì¶œë ¥í•œë‹¤.
   ë‚´ë¶€ ê²€í†  ê³¼ì •Â·ì´ˆì•ˆÂ·ìê¸°í‰ê°€ëŠ” ì–´ë–¤ í˜•ì‹ìœ¼ë¡œë„ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.

[ì—­í• ]
- ë„ˆëŠ” â€œìƒí’ˆëª… ì •ì œâ€ë§Œ ë‹´ë‹¹í•œë‹¤.
- ì›ë³¸ ìƒí’ˆëª…ê³¼ ì¹´í…Œê³ ë¦¬ëª…ì„ í•¨ê»˜ ì°¸ê³ í•˜ì—¬, ì˜¨ë¼ì¸ ìœ„íƒíŒë§¤ìš©ìœ¼ë¡œ ì í•©í•œ ì •ë³´ ì¤‘ì‹¬ ìƒí’ˆëª…ì„ ë§Œë“¤ì–´ì•¼ í•œë‹¤.
- ì´ ë‹¨ê³„ì˜ ìƒí’ˆëª…ì€ â€œìµœì¢… ë…¸ì¶œìš©â€ì´ ì•„ë‹ˆë¼, ì´í›„ ë‹¨ê³„(Stage 2, 3)ì—ì„œ ì°¸ê³ í•  **ì •ì œ ë²„ì „**ì´ë¼ëŠ” ì ì„ ê¸°ì–µí•œë‹¤.

[ìœ„íƒíŒë§¤ íŠ¹ì´ ê·œì¹™]
- ë¸Œëœë“œ ê²½ìŸë ¥ì´ ì—†ìœ¼ë¯€ë¡œ, ì¼ë°˜ì ì¸ ë¸Œëœë“œëª…/ìƒµëª…ì€ ìƒí’ˆëª…ì—ì„œ ì œê±°í•œë‹¤.
  - ì˜ˆ: ë‚˜ì´í‚¤, ì•„ë””ë‹¤ìŠ¤, â—‹â—‹ìƒµ, â—‹â—‹ëª°, ì—˜ë¦¬ìŠ¤, â—‹â—‹ë§ˆì¼“ ë“±ì€ ëª¨ë‘ ì œê±°.
  - ë‹¨, â€œí”¼ì¹˜ê¸°ëª¨, ì¿ ì…˜í¼, ìˆ˜ì œ, í•¸ë“œë©”ì´ë“œ, DIYâ€ì²˜ëŸ¼ **ê¸°ëŠ¥Â·ì¬ì§ˆÂ·íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´**ëŠ” ë¸Œëœë“œê°€ ì•„ë‹ˆë¼ ì†ì„±ìœ¼ë¡œ ë³´ê³  ìœ ì§€í•œë‹¤.
- â€œ/â€, â€œÂ·â€, â€œ,â€ ê°™ì€ ê¸°í˜¸ëŠ” ë˜ë„ë¡ ì‚¬ìš©í•˜ì§€ ë§ê³ , ë„ì–´ì“°ê¸°ë¡œ ëŒ€ì²´í•œë‹¤.
  - ì˜ˆ: â€œí…€ë¸”ëŸ¬/ì»µí™€ë”â€ â†’ â€œí…€ë¸”ëŸ¬ ì»µí™€ë”â€

[ì¶”ê°€ ë©”íƒ€ ì •ë³´]
- ì´ ìƒí’ˆì˜ íŒë§¤í˜•íƒœëŠ” â€œë‹¨í’ˆí˜•â€ ë˜ëŠ” â€œì˜µì…˜í˜•â€ ì¤‘ í•˜ë‚˜ì´ë‹¤.
  - "ë‹¨í’ˆí˜•"ì´ë©´ ì˜µì…˜ ì—†ì´ 1ê°œ êµ¬ì„±,
  - "ì˜µì…˜í˜•"ì´ë©´ ìƒ‰ìƒ/ì‚¬ì´ì¦ˆ/íƒ€ì… ë“± ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒí•˜ëŠ” êµ¬ì¡°ì´ë‹¤.
- ì´ ì •ë³´ëŠ” ì°¸ê³ ìš©ì¼ ë¿, ìƒí’ˆëª… ì•ˆì— ì–µì§€ë¡œ "ë‹¨í’ˆí˜•/ì˜µì…˜í˜•" ê°™ì€ ë‹¨ì–´ë¥¼ ë„£ì„ í•„ìš”ëŠ” ì—†ë‹¤.

[ìµœì¢… ëª©í‘œ]
- ê³¼ì¥ í‘œí˜„ ì—†ì´, ê²€ìƒ‰ê³¼ ë…¸ì¶œì— ë„ì›€ì´ ë˜ëŠ” â€œì •ë³´ ìœ„ì£¼ ìƒí’ˆëª…â€ì„ ì‘ì„±í•œë‹¤.
- ë¸Œëœë“œÂ·ìƒì  ì •ë³´ì™€ ê´‘ê³  ë¬¸êµ¬ëŠ” ì œê±°í•˜ê³ , ì œí’ˆì˜ ì •ì²´(ë¬´ì—‡ì¸ì§€)ì™€ ê¸°ëŠ¥Â·ìƒí™©Â·ìŠ¤í™ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•œë‹¤.
- ìµœì¢… ì¶œë ¥ì€ â€œì •ì œëœ ìƒí’ˆëª… í•œ ì¤„â€ë§Œ ë‚¨ë„ë¡ í•œë‹¤.

[ì‘ì—… ìˆœì„œ]

1ë‹¨ê³„. ì›ë³¸ ì´í•´
- user ë©”ì‹œì§€ë¡œ ì£¼ì–´ì§€ëŠ” "ì¹´í…Œê³ ë¦¬ëª…"ê³¼ "ì›ë³¸ ìƒí’ˆëª…"ì„ í•¨ê»˜ ë³´ê³  ì¹´í…Œê³ ë¦¬/ì œí’ˆêµ°ì„ ë¨¼ì € íŒŒì•…í•œë‹¤.
- ë‹¤ìŒ â€œí•µì‹¬ ì •ë³´â€ë¥¼ ë¨¸ë¦¿ì†ì— ì •ë¦¬í•œë‹¤.
  - í•µì‹¬ ì œí’ˆêµ°/íƒ€ì… (ì˜ˆ: ëŸ¬ë‹í™”, ê°€ëœë“œ, ë‚˜ë…¸ë¸”ëŸ­, ì„ ë¬¼ì£¼ë¨¸ë‹ˆ, ë°©í•œëª¨ì, ìŠ¤ë…¸ìš°ì²´ì¸, ì¿ ì…˜í¼ë²½ì§€ ë“±)
  - í•µì‹¬ ê¸°ëŠ¥Â·íš¨ê³¼ ë˜ëŠ” ì‚¬ìš©ìƒí™© (ì˜ˆ: ë°©í•œ, ë‹¨ì—´, ê³°íŒ¡ì´ë°©ì§€, ë¬´ì†ŒìŒ, ì•ˆë²—ê²¨ì§, ë¹„ìƒìš©, ìº í•‘ìš© ë“±)
  - ê·œê²©/ì‚¬ì´ì¦ˆ/ìš©ëŸ‰/ìˆ˜ëŸ‰ (ì˜ˆ: 12L, 50cm x 2.5m, 100ê°œì… ë“±)
  - ì‚¬ìš©ëŒ€ìƒ/í•/ìŠ¤íƒ€ì¼ (ì˜ˆ: ë‚¨ì„± ì„¸ë¯¸ì¼ì, ì—¬ì„± ë§ì‹ , ìˆ˜í—˜ìƒ ì‹œê³„, ìº í•‘ìš© í•˜ë“œì¿¨ëŸ¬ ë“±)
  - í•„ìš”í•œ ê²½ìš° ìƒ‰ìƒ/ì˜µì…˜, ì‹œì¦ŒÂ·í…Œë§ˆ (ê²¨ìš¸ìš©, í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ìˆ˜ëŠ¥ ë“±)

2ë‹¨ê³„. ë…¸ì´ì¦ˆ(ê´‘ê³ /ìƒì /ë¸Œëœë“œ ì •ë³´) ì œê±°
- ì•„ë˜ì™€ ê°™ì€ ê´‘ê³ ì„± í‘œí˜„ ë° ìƒì  ê´€ë ¨ ì •ë³´ëŠ” ì „ë¶€ ì œê±°í•œë‹¤.
  - ì˜ˆì‹œ ê´‘ê³  ë¬¸êµ¬:
    â€œë¬´ë£Œë°°ì†¡â€, â€œë‹¹ì¼ë°°ì†¡â€, â€œì˜¤ëŠ˜ì¶œë°œâ€, â€œí–‰ì‚¬â€, â€œì¸ê¸°â€, â€œê°•ë ¥ì¶”ì²œâ€, â€œìµœì €ê°€â€, â€œë¹…ì„¸ì¼â€, â€œíŠ¹ê°€â€, â€œì¸ì‹¸í…œâ€, â€œMDì¶”ì²œâ€, â€œí•œì •ìˆ˜ëŸ‰â€, â€œêµ­ë¯¼í…œâ€, â€œí•«ë”œâ€ ë“±
  - ì´ëª¨í‹°ì½˜/ê¸°í˜¸:
    â€œâ™¥â€, â€œâ˜…â€, â€œâ™¬â€, â€œâ€»â€, â€œ!!â€, â€œ??â€ ë“±
  - ìƒì Â·ëª° ì´ë¦„:
    â€œâ—‹â—‹ëª°â€, â€œâ—‹â—‹ìƒµâ€, â€œâ—‹â—‹ìŠ¤í† ì–´â€, â€œê³µì‹ëª°â€, â€œì „ë¬¸ëª°â€, â€œì§ì˜ëª°â€ ë“±
  - ì¼ë°˜ì ì¸ ë¸Œëœë“œëª…:
    ë‚˜ì´í‚¤, ì•„ë””ë‹¤ìŠ¤, â—‹â—‹ë§ˆì¼“, â—‹â—‹ë¸Œëœë“œ ë“± ìœ„íƒíŒë§¤ìê°€ ê²½ìŸ ìš°ìœ„ë¥¼ ê°–ì§€ ëª»í•˜ëŠ” ë¸Œëœë“œëª…
  - ì—°ë½ì²˜Â·í™ë³´:
    ì „í™”ë²ˆí˜¸, ì¹´ì¹´ì˜¤í†¡ ID, URL, SNS ì•„ì´ë”” ë“±
- ìœ„ ì˜ˆì‹œëŠ” ì°¸ê³ ìš©ì´ë©°, ì´ì™€ ìœ ì‚¬í•œ ëª¨ë“  ê´‘ê³ ì„±Â·í™ë³´ì„±Â·ë¸Œëœë“œ ë¬¸êµ¬ë„ í•¨ê»˜ ì œê±°í•œë‹¤.

3ë‹¨ê³„. ê´„í˜¸Â·ê¸°í˜¸ ì •ë¦¬
- ê´„í˜¸ëŠ” í•„ìš”í•œ ìµœì†Œ ê°œìˆ˜ë§Œ ì‚¬ìš©í•œë‹¤.
- ì˜ë¯¸ ìˆëŠ” ì •ë³´ëŠ” ì‚´ë¦¬ê³ , ê´„í˜¸ ê¸°í˜¸ë§Œ ì •ë¦¬í•œë‹¤.
  - ì˜ˆ: â€œ(ë¸”ë£¨)â€ â†’ â€œë¸”ë£¨â€, â€œ(ë ˆí„°ì‚°íƒ€)â€ â†’ â€œë ˆí„° ì‚°íƒ€â€
- ì´ì¤‘ ê´„í˜¸Â·ë¶ˆí•„ìš”í•œ ê´„í˜¸Â·ë¹ˆ ê´„í˜¸ëŠ” ì œê±°í•œë‹¤.
  - ì˜ˆ: â€œ(( ))â€, â€œ()â€ ë“±ì€ ì‚­ì œ.
- â€œ/â€, â€œÂ·â€, â€œ,â€ ë“± ê¸°í˜¸ëŠ” ë˜ë„ë¡ ì‚¬ìš©í•˜ì§€ ë§ê³ , ë‹¨ìˆœí•œ ë„ì–´ì“°ê¸°ë¡œ ë°”ê¾¼ë‹¤.

4ë‹¨ê³„. í•µì‹¬ ì •ë³´ ìœ ì§€ & êµ¬ì¡°í™”
- ë°˜ë“œì‹œ ìœ ì§€í•´ì•¼ í•  ì •ë³´:
  - í•µì‹¬ ì œí’ˆêµ°/íƒ€ì… (ì˜ˆ: ëŸ¬ë‹í™”, ê°€ëœë“œ, ë‚˜ë…¸ë¸”ëŸ­, ì„ ë¬¼ì£¼ë¨¸ë‹ˆ, ë°©í•œëª¨ì, ìŠ¤ë…¸ìš°ì²´ì¸, ì¿ ì…˜í¼ë²½ì§€ ë“±)
  - í•µì‹¬ ê¸°ëŠ¥Â·íš¨ê³¼/ì‚¬ìš©ìƒí™© (ì˜ˆ: ë°©í•œìš©, ë‹¨ì—´ìš©, ê³°íŒ¡ì´ë°©ì§€ìš©, ë¬´ì†ŒìŒ ì‹œí—˜ìš©, ë¹„ìƒìš©, ìº í•‘ìš© ë“±)
  - ê·œê²©Â·ìš©ëŸ‰/ì„¸íŠ¸Â·ìˆ˜ëŸ‰ (ì˜ˆ: 12L, 100ê°œì…, 50cm x 2.5m, 4P ì„¸íŠ¸ ë“±)
  - ì‚¬ìš©ëŒ€ìƒÂ·ìŠ¤íƒ€ì¼/í• (ì˜ˆ: ë‚¨ì„± ì„¸ë¯¸ì¼ì, ì—¬ì„± í˜ì´í¬ì‚­ìŠ¤, ìˆ˜í—˜ìƒìš©, ìº í•‘Â·ì•„ì›ƒë„ì–´ìš© ë“±)
  - í•„ìš”í•œ ê²½ìš° ìƒ‰ìƒÂ·ì˜µì…˜, ì‹œì¦ŒÂ·í…Œë§ˆ
- ì˜ë¯¸ ì—†ëŠ” ì¤‘ë³µ ë‹¨ì–´ì™€ ëª¨í˜¸í•œ ìˆ˜ì‹ì–´ëŠ” ì¤„ì¸ë‹¤.
- í•µì‹¬ í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì¼ê´€ëœ ìˆœì„œë¡œ ì¬ë°°ì¹˜í•œë‹¤.
  - ì˜ˆ:
    ì›ë³¸: â€œí¬ë¦¬ìŠ¤ë§ˆìŠ¤íŒŒí‹°ê°€ëœë“œ(ë ˆí„°ì‚°íƒ€) íŒŒí‹°ìš©í’ˆ ì¥ì‹ ì†Œí’ˆâ€  
    ì •ì œ: â€œí¬ë¦¬ìŠ¤ë§ˆìŠ¤ íŒŒí‹° ê°€ëœë“œ ë ˆí„° ì‚°íƒ€ ì¥ì‹ ì†Œí’ˆâ€

5ë‹¨ê³„. ìœ„í—˜í•œ ë³€ì¡° ê¸ˆì§€
- ì‹¤ì œ ì›ë³¸ì— ì—†ëŠ” ì •ë³´ë¥¼ ìƒˆë¡œ ë§Œë“¤ì–´ë‚´ì§€ ì•ŠëŠ”ë‹¤.
  - ì¬ì§ˆ, ìš©ëŸ‰, ê¸°ëŠ¥, ì¸ì¦ ì •ë³´ë¥¼ ì¶”ì¸¡ìœ¼ë¡œ ì¶”ê°€í•˜ë©´ ì•ˆ ëœë‹¤.
- ìˆ«ì, ëª¨ë¸ëª…, ìš©ëŸ‰, ì‚¬ì´ì¦ˆëŠ” ì›ë³¸ì— ìˆëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.
- í•œê¸€/ì˜ë¬¸ í‘œê¸°ëŠ” ì›ë³¸ì„ ì¡´ì¤‘í•˜ë˜, ë¶ˆí•„ìš”í•œ ë°˜ë³µì´ë‚˜ ì–´ìƒ‰í•œ í‘œê¸°ëŠ” ì •ëˆí•œë‹¤.
  - ì˜ˆ: â€œX-masâ€ì™€ â€œí¬ë¦¬ìŠ¤ë§ˆìŠ¤â€ê°€ í•¨ê»˜ ìˆìœ¼ë©´, ìƒí™©ì— ë§ê²Œ í•œ í˜•íƒœë¡œë§Œ í†µì¼.

6ë‹¨ê³„. ê¸¸ì´ ë° í˜•ì‹ ì œí•œ
- ì •ì œëœ ìƒí’ˆëª…ì€ â€œìµœëŒ€ 60ì ì´ë‚´â€ë¡œ ì‘ì„±í•œë‹¤.
- 60ìë¥¼ ì´ˆê³¼í•˜ë©´, ì¤‘ìš”ë„ê°€ ë‚®ì€ ìˆ˜ì‹ì–´ë¶€í„° ìˆœì„œëŒ€ë¡œ ì œê±°í•´ 60ì ì´ë‚´ë¡œ ì¤„ì¸ë‹¤.
- ë¬¸ì¥ì´ ì•„ë‹ˆë¼ â€œìƒí’ˆëª… í˜•íƒœâ€ë¡œ ì‘ì„±í•œë‹¤.
  - â€œ~ì…ë‹ˆë‹¤â€, â€œ~í•´ìš”â€, â€œì–´ë– ì„¸ìš”?â€ ê°™ì€ ë¬¸ì¥í˜• í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ì´ëª¨í‹°ì½˜, ê³¼ì¥ëœ ëŠë‚Œí‘œ, ì˜ë¯¸ ì—†ëŠ” ê¸°í˜¸ëŠ” ëª¨ë‘ ì œê±°í•œë‹¤.

7ë‹¨ê³„. ì…ë ¥ & ì¶œë ¥ í˜•ì‹
- user ë©”ì‹œì§€ë¡œ ì „ë‹¬ë˜ëŠ” ì•„ë˜ ì…ë ¥ ì •ë³´ë¥¼ ì°¸ê³ í•´ ìƒí’ˆëª…ì„ ì •ì œí•œë‹¤.
  - ì¹´í…Œê³ ë¦¬ëª…
  - íŒë§¤í˜•íƒœ
  - ì›ë³¸ ìƒí’ˆëª…
- ì¶œë ¥ ê·œì¹™:
  - ì˜¤ì§ â€œì •ì œëœ ìƒí’ˆëª… í•œ ì¤„â€ë§Œ ì¶œë ¥í•œë‹¤.
  - ë”°ì˜´í‘œ(â€œ â€, ' ')ë¡œ ê°ì‹¸ì§€ ì•ŠëŠ”ë‹¤.
  - â€œì •ì œëœ ìƒí’ˆëª…: â€¦â€ ê°™ì€ ë¼ë²¨Â·ì„¤ëª… ë¬¸êµ¬ë¥¼ ë¶™ì´ì§€ ì•ŠëŠ”ë‹¤.
  - ë‹¨ê³„ ì„¤ëª…, ì´ìœ , í•´ì„¤, ë©”ëª¨, ì¶”ê°€ ë¬¸ì¥ì€ ì ˆëŒ€ ì“°ì§€ ì•ŠëŠ”ë‹¤.
"""

# ê° í–‰ë§ˆë‹¤ ë™ì ìœ¼ë¡œ ë¶™ëŠ” user í”„ë¡¬í”„íŠ¸(ì§§ì€ ë¶€ë¶„ë§Œ ë°˜ë³µ)
STAGE1_USER_PROMPT_TEMPLATE = """[ì…ë ¥ ì •ë³´]
- ì¹´í…Œê³ ë¦¬ëª…: {category}
- íŒë§¤í˜•íƒœ: {sale_type}
- ì›ë³¸ ìƒí’ˆëª…: {raw_name}

ì´ì œ ìœ„ ê·œì¹™ì„ ì ìš©í•˜ì—¬ ì•„ë˜ ì›ë³¸ ìƒí’ˆëª…ì„ ì •ì œí•˜ë¼.
ì •ì œí•  ìƒí’ˆëª… : "{raw_name}"
"""


# =========================
# ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ìœ í‹¸
# =========================

def looks_like_response_id(s: str) -> bool:
    """resp_xxxxx í˜•íƒœì˜ Response ID ê°™ì€ ë¬¸ìì—´ì€ ë²„ë¦¬ê¸°."""
    if not s:
        return False
    if not s.startswith("resp_"):
        return False
    tail = s[5:]
    return bool(re.fullmatch(r"[0-9a-f]{16,}", tail))


def _extract_from_text_obj(text_obj: Any) -> str:
    """content[*].text ê°ì²´ì—ì„œ ë¬¸ìì—´ì„ ìµœëŒ€í•œ ë½‘ì•„ë‚¸ë‹¤."""
    # ì´ë¯¸ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ
    if isinstance(text_obj, str):
        return text_obj.strip()

    # value ì†ì„± ì‹œë„ (Responses ê³µì‹ êµ¬ì¡°)
    val = getattr(text_obj, "value", None)
    if isinstance(val, str) and val.strip():
        return val.strip()

    # dict ë¹„ìŠ·í•œ êµ¬ì¡°ë©´ ì•ˆìª½ì—ì„œ value/text ì°¾ê¸°
    data = None
    try:
        if hasattr(text_obj, "model_dump"):
            data = text_obj.model_dump()
        elif isinstance(text_obj, dict):
            data = text_obj
        else:
            data = getattr(text_obj, "__dict__", None)
    except Exception:
        data = None

    if isinstance(data, dict):
        for key in ("value", "text", "content"):
            v = data.get(key)
            if isinstance(v, str) and v.strip():
                return v.strip()

    # ë§ˆì§€ë§‰ fallback: ê·¸ëƒ¥ str() í•´ë³´ê³  ì¨ë¨¹ì„ ìˆ˜ ìˆìœ¼ë©´ ì‚¬ìš©
    try:
        s = str(text_obj)
        if s and not s.startswith("<") and not s.endswith(">"):
            return s.strip()
    except Exception:
        pass

    return ""


def extract_text_from_response(response: Any, prompt_hint: Optional[str] = None) -> str:
    """
    OpenAI responses.create ì‘ë‹µ ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ.

    1ìˆœìœ„: response.output[0].content[0].text(.value)
    2ìˆœìœ„: response.output_text / response.text
    3ìˆœìœ„: model_dump()ë¡œ JSON ì „ì²´ë¥¼ í›‘ì–´ì„œ ë¬¸ìì—´ í›„ë³´ë¥¼ ëª¨ì€ ë’¤,
           í”„ë¡¬í”„íŠ¸ì™€ì˜ ìœ ì‚¬ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 'ë‹µë³€ í…ìŠ¤íŠ¸'ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²ƒì„ ì„ íƒ.
    """

    # --- 1) ê³µì‹ output êµ¬ì¡° ìš°ì„  ì‹œë„ ---
    try:
        output = getattr(response, "output", None)
        if output:
            # ë¦¬ìŠ¤íŠ¸ / íŠœí”Œ / ë‹¨ì¼ ê°ì²´ ëª¨ë‘ ëŒ€ì‘
            items = output
            if not isinstance(items, (list, tuple)):
                items = [items]

            for item in items:
                # dict / ê°ì²´ ëª¨ë‘ ì²˜ë¦¬
                if isinstance(item, dict):
                    content = item.get("content")
                else:
                    content = getattr(item, "content", None)

                if not content:
                    continue

                # dict / ë¦¬ìŠ¤íŠ¸ ëª¨ë‘ ì²˜ë¦¬
                if isinstance(content, dict):
                    content_list = [content]
                else:
                    content_list = list(content)

                for c in content_list:
                    if isinstance(c, dict):
                        text_obj = c.get("text")
                    else:
                        text_obj = getattr(c, "text", None)
                    if text_obj is None:
                        continue
                    s = _extract_from_text_obj(text_obj)
                    if s:
                        return s.strip()
    except Exception:
        pass

    # --- 2) SDK í¸ì˜ ì†ì„± ì‹œë„ ---
    for attr in ("output_text", "text"):
        val = getattr(response, attr, None)
        if isinstance(val, str) and val.strip():
            return val.strip()

        if val is not None and not isinstance(val, str):
            v = getattr(val, "value", None)
            if isinstance(v, str) and v.strip():
                return v.strip()
            if isinstance(val, dict):
                for k in ("value", "text"):
                    txt = val.get(k)
                    if isinstance(txt, str) and txt.strip():
                        return txt.strip()

    # --- 3) ì „ì²´ JSONì„ í›‘ì–´ì„œ í›„ë³´ ë¬¸ìì—´ ì°¾ê¸° (ë§ˆì§€ë§‰ fallback) ---
    data = None
    try:
        if hasattr(response, "model_dump"):
            data = response.model_dump()
        elif hasattr(response, "dict"):
            data = response.dict()
    except Exception:
        data = None

    if not isinstance(data, dict):
        return ""

    strings: list[str] = []

    def _collect_strings(obj, acc):
        """ì¤‘ì²©ëœ dict/list êµ¬ì¡°ì—ì„œ ëª¨ë“  ë¬¸ìì—´ì„ ìˆ˜ì§‘."""
        if isinstance(obj, str):
            s = obj.strip()
            if s:
                acc.append(s)
        elif isinstance(obj, dict):
            for k, v in obj.items():
                # í”„ë¡¬í”„íŠ¸/ì§€ì‹œë¬¸/ID/ëª¨ë¸ëª… ë“±ì€ ì œì™¸
                if k in ("prompt", "input", "instructions", "id", "model", "object", "type", "role"):
                    continue
                _collect_strings(v, acc)
        elif isinstance(obj, (list, tuple)):
            for x in obj:
                _collect_strings(x, acc)

    _collect_strings(data, strings)

    # í›„ë³´ ì •ì œ
    uniq = []
    seen = set()
    for s in strings:
        if s in seen:
            continue
        seen.add(s)
        uniq.append(s)

    candidates = []
    for s in uniq:
        # resp_... ê°™ì€ IDëŠ” ë²„ë¦¬ê¸°
        if looks_like_response_id(s):
            continue

        # í”„ë¡¬í”„íŠ¸ë‘ ì™„ì „íˆ ê°™ì€ ë¬¸ìì—´ì€ ì œì™¸
        if prompt_hint and s == prompt_hint:
            continue
        # ë„ˆë¬´ ì§§ê±°ë‚˜(1ê¸€ì) ë„ˆë¬´ ê¸´ ê²ƒ(ì„¤ëª…ë¬¸ ë“±)ì€ ì œì™¸
        if len(s) < 2 or len(s) > 200:
            continue
        # í”„ë¡¬í”„íŠ¸ ì•ˆì— ê±°ì˜ ê·¸ëŒ€ë¡œ í¬í•¨ëœ ê¸´ ë¬¸ì¥(í”„ë¡¬í”„íŠ¸ ì¼ë¶€)ë„ ì œì™¸
        if prompt_hint and s in prompt_hint and len(s) > len(prompt_hint) * 0.5:
            continue

        candidates.append(s)

    if not candidates:
        return ""

    # ê³µë°±ì´ ìˆê³ , ì–´ëŠ ì •ë„ ê¸¸ì´ê°€ ìˆëŠ” ë¬¸ìì—´ì¼ìˆ˜ë¡ "ë¬¸ì¥/ìƒí’ˆëª…"ì¼ ê°€ëŠ¥ì„±ì´ í¬ë‹¤ê³  ê°€ì •
    best = max(candidates, key=lambda s: (s.count(" "), len(s)))
    return best.strip()


# =========================
# OpenAI í˜¸ì¶œ í•¨ìˆ˜
# =========================

def call_stage1_model(
    row_prompt: str,
    system_prompt: str,
    model: str = "gpt-5-nano",
    temperature: float = 0.2,
    max_output_tokens: int = DEFAULT_MAX_OUTPUT_TOKENS,
    max_retries: int = 3,
    debug_log=None,
) -> Tuple[str, int, int]:
    """
    Stage1 í”„ë¡¬í”„íŠ¸ 1ê°œë¥¼ OpenAIì— ë³´ë‚´ê³ ,
    ì •ì œëœ ìƒí’ˆëª…(í…ìŠ¤íŠ¸)ì™€ í† í° ì‚¬ìš©ëŸ‰ì„ ë°˜í™˜.

    ë°˜í™˜: (result_text, input_tokens, output_tokens)
    """
    global client

    row_prompt = safe_str(row_prompt)
    system_prompt = safe_str(system_prompt)
    if not row_prompt:
        return "", 0, 0

    if client is None:
        raise RuntimeError("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    last_err: Optional[Exception] = None

    for attempt in range(1, max_retries + 1):
        try:
            # Responses API: instructions(=system), input(=user)
            kwargs = {
                "model": model,
                "instructions": system_prompt,
                "input": row_prompt,
                "max_output_tokens": max_output_tokens,
            }

            # gpt-5 ê³„ì—´ì€ reasoning ëª¨ë¸ â†’ temperature ë¬´ì‹œ, reasoning.effort ì‚¬ìš©
            if model.startswith("gpt-5"):
                kwargs["reasoning"] = {"effort": "medium"}
            else:
                kwargs["temperature"] = temperature

            response = client.responses.create(**kwargs)

            # === Debug: ì „ì²´ response ë¤í”„ ===
            if debug_log is not None:
                try:
                    debug_log("[DEBUG] raw response ê°ì²´:")
                    debug_log(str(response))

                    if hasattr(response, "model_dump_json"):
                        debug_log("[DEBUG] response.model_dump_json():")
                        debug_log(response.model_dump_json(indent=2))
                    elif hasattr(response, "model_dump"):
                        debug_log("[DEBUG] response.model_dump():")
                        debug_log(json.dumps(response.model_dump(), ensure_ascii=False, indent=2))
                except Exception as e:
                    debug_log(f"[DEBUG] response ë¤í”„ ì¤‘ ì˜¤ë¥˜: {e}")

            # === ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ===
            result_text = extract_text_from_response(response, prompt_hint=row_prompt)

            usage = getattr(response, "usage", None)
            in_tokens = getattr(usage, "input_tokens", 0) if usage else 0
            out_tokens = getattr(usage, "output_tokens", 0) if usage else 0

            # ë””ë²„ê¹…: í…ìŠ¤íŠ¸ê°€ ì™„ì „íˆ ë¹„ì—ˆëŠ”ë° í† í°ì€ ì†Œë¹„ëœ ê²½ìš°ë§Œ ê²½ê³ 
            if (in_tokens or out_tokens) and not result_text:
                if debug_log is not None:
                    debug_log("[WARN] ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. JSON êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    print("[WARN] ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. JSON êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            return result_text, in_tokens, out_tokens

        except Exception as e:
            last_err = e
            err_str = str(e)

            # ì—ëŸ¬ ë¬¸ìì—´ì—ì„œ status code ì¶”ì¶œ (ì˜ˆ: "Error code: 404 - {...}")
            m = re.search(r"Error code:\s*(\d+)", err_str)
            status_code = int(m.group(1)) if m else None

            if debug_log is not None:
                debug_log(f"[WARN] OpenAI í˜¸ì¶œ ì‹¤íŒ¨({attempt}/{max_retries}) - {err_str}")
            else:
                print(f"[WARN] OpenAI í˜¸ì¶œ ì‹¤íŒ¨({attempt}/{max_retries}) - {err_str}")

            # ëª¨ë¸ ì—†ìŒ(404), quota ë¶€ì¡±(429)ì€ ì¬ì‹œë„í•´ë„ ì˜ë¯¸ ì—†ìŒ â†’ ë°”ë¡œ ì¤‘ë‹¨
            if status_code in (404, 429):
                break

    # ì—¬ê¸°ê¹Œì§€ ì™”ìœ¼ë©´ ì‹¤íŒ¨
    raise RuntimeError(f"OpenAI í˜¸ì¶œ ë°˜ë³µ ì‹¤íŒ¨: {last_err}")


# =========================
# ì—‘ì…€ ì²˜ë¦¬ ë©”ì¸ ë¡œì§
# =========================

def run_stage1_on_excel(
    excel_path: str,
    model: str,
    temperature: float,
    max_output_tokens: int,
    save_every: int,
    overwrite: bool,
    log_func=print,
) -> str:
    """
    Stage1 ë§µí•‘ ì—‘ì…€ì„ ì½ì–´ì„œ ê° í–‰ì˜
    (ì¹´í…Œê³ ë¦¬ëª…, íŒë§¤í˜•íƒœ, ì›ë³¸ìƒí’ˆëª…)ì„ ê¸°ë°˜ìœ¼ë¡œ
    OpenAIë¥¼ í˜¸ì¶œí•˜ê³ , ST1_ì •ì œìƒí’ˆëª…ì„ ì±„ì›Œ ë„£ëŠ”ë‹¤.
    """
    global STOP_REQUESTED

    log = log_func
    log(f"[INFO] ì—‘ì…€ ë¡œë“œ: {excel_path}")

    df = pd.read_excel(excel_path, dtype=str)

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    required_cols = ["ì¹´í…Œê³ ë¦¬ëª…", "ì›ë³¸ìƒí’ˆëª…", "íŒë§¤í˜•íƒœ"]
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"ì—‘ì…€ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

    # ê²°ê³¼ ì»¬ëŸ¼ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if "ST1_ì •ì œìƒí’ˆëª…" not in df.columns:
        df["ST1_ì •ì œìƒí’ˆëª…"] = ""

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    base_dir = os.path.dirname(excel_path)
    base_name = os.path.splitext(os.path.basename(excel_path))[0]
    out_path = os.path.join(base_dir, f"{base_name}_stage1_completed.xlsx")

    total_rows = len(df)
    log(f"[INFO] ì´ í–‰ ìˆ˜: {total_rows}")
    if model.startswith("gpt-5"):
        log(f"[INFO] ì‚¬ìš©í•  ëª¨ë¸: {model} (reasoning.effort=medium, temperature ë¬´ì‹œ)")
    else:
        log(f"[INFO] ì‚¬ìš©í•  ëª¨ë¸: {model}")
        log(f"[INFO] temperature: {temperature:.2f}")
    log(f"[INFO] max_output_tokens: {max_output_tokens}")
    log(f"[INFO] save_every: {save_every}, overwrite: {overwrite}")

    processed = 0
    total_in_tokens = 0
    total_out_tokens = 0

    for idx, row in df.iterrows():
        # ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ í™•ì¸
        if STOP_REQUESTED:
            log("[INFO] ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ ê°ì§€. í˜„ì¬ê¹Œì§€ ì§„í–‰ëœ ê²°ê³¼ë§Œ ì €ì¥í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        category = safe_str(row.get("ì¹´í…Œê³ ë¦¬ëª…", ""))
        raw_name = safe_str(row.get("ì›ë³¸ìƒí’ˆëª…", ""))
        sale_type = safe_str(row.get("íŒë§¤í˜•íƒœ", ""))

        if not raw_name:
            continue

        current_result = safe_str(row.get("ST1_ì •ì œìƒí’ˆëª…", ""))
        if current_result and not overwrite:
            # ì´ë¯¸ ê²°ê³¼ê°€ ìˆê³  ë®ì–´ì“°ê¸° ì˜µì…˜ì´ ì•„ë‹ˆë©´ ìŠ¤í‚µ
            continue

        # í–‰ë³„ user í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        row_prompt = STAGE1_USER_PROMPT_TEMPLATE.format(
            category=category,
            sale_type=sale_type,
            raw_name=raw_name,
        )

        log(f"\n[INFO] í–‰ {idx} ì²˜ë¦¬ ì¤‘...")
        log(f"      ì›ë³¸ìƒí’ˆëª…: {raw_name}")
        log(f"      ì¹´í…Œê³ ë¦¬ëª…: {category}")
        log(f"      íŒë§¤í˜•íƒœ: {sale_type}")

        try:
            result_text, in_tok, out_tok = call_stage1_model(
                row_prompt=row_prompt,
                system_prompt=STAGE1_SYSTEM_PROMPT,
                model=model,
                temperature=temperature,
                max_output_tokens=max_output_tokens,
                debug_log=log,   # ğŸ” ì—¬ê¸°ì„œ ì „ì²´ response ë¡œê·¸ë¡œ í™•ì¸
            )
        except Exception as e:
            msg = str(e)
            log(f"[ERROR] í–‰ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {msg}")

            # quota ë¶€ì¡± â†’ ë” ì§„í–‰í•´ë„ ì „ë¶€ ì‹¤íŒ¨í•˜ë¯€ë¡œ ì¦‰ì‹œ ì¤‘ë‹¨
            if "insufficient_quota" in msg or "You exceeded your current quota" in msg:
                log("[ERROR] OpenAI í¬ë ˆë”§/ìš”ê¸ˆ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                log("[ERROR] platform.openai.comì—ì„œ ê²°ì œ/í•œë„ë¥¼ í™•ì¸í•œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
                break

            # ëª¨ë¸ ì—†ìŒ / ê¶Œí•œ ì—†ìŒ â†’ ì¦‰ì‹œ ì¤‘ë‹¨
            if "model_not_found" in msg or "does not exist" in msg:
                log("[ERROR] ì„ íƒí•œ ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
                log("[ERROR] ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
                break

            # ê·¸ ì™¸ ì—ëŸ¬ëŠ” í•´ë‹¹ í–‰ë§Œ ê±´ë„ˆë›°ê³  ë‹¤ìŒ í–‰ìœ¼ë¡œ ì§„í–‰
            continue

        # ê²°ê³¼ ê¸°ë¡
        df.at[idx, "ST1_ì •ì œìƒí’ˆëª…"] = result_text
        processed += 1
        total_in_tokens += in_tok
        total_out_tokens += out_tok

        log(f"[OK] í–‰ {idx} ì™„ë£Œ")
        log(f"     ê²°ê³¼: {result_text}")
        if in_tok or out_tok:
            log(f"     tokens in/out = {in_tok}/{out_tok}")

        # ì¤‘ê°„ ì €ì¥
        if processed > 0 and processed % save_every == 0:
            log(f"[INFO] {processed}ê°œ ì²˜ë¦¬, ì¤‘ê°„ ì €ì¥: {out_path}")
            df.to_excel(out_path, index=False)

    # ìµœì¢… ì €ì¥
    log(f"\n[INFO] ìµœì¢… ì €ì¥: {out_path}")
    df.to_excel(out_path, index=False)

    log(f"[INFO] ì²˜ë¦¬ ì™„ë£Œ. ìƒˆë¡œ ì²˜ë¦¬ëœ í–‰ ìˆ˜: {processed}")
    log(f"[INFO] ì´ í† í° ì‚¬ìš©ëŸ‰: input={total_in_tokens}, output={total_out_tokens}")

    return out_path


# =========================
# Tkinter GUI
# =========================

class Stage1APIRunnerApp:
    def __init__(self, root: tk.Tk):
        self.root = root
        root.title("Stage1 ìƒí’ˆëª… ì •ì œ API ì‹¤í–‰ê¸°")
        root.geometry("920x650")

        self.selected_file: Optional[str] = None

        # ----- ìƒë‹¨ ì„¤ëª… -----
        desc = (
            "â‘  ëŒ€ìƒ íŒŒì¼\n"
            "   - Stage1 ë§µí•‘ íˆ´(API ë²„ì „)ë¡œ ìƒì„±í•œ '*_stage1_mapping_api.xlsx' íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\n"
            "â‘¡ í•„ìˆ˜ ì»¬ëŸ¼\n"
            "   - ì¹´í…Œê³ ë¦¬ëª…, ì›ë³¸ìƒí’ˆëª…, íŒë§¤í˜•íƒœ, ST1_ì •ì œìƒí’ˆëª…(ì—†ìœ¼ë©´ ìë™ ìƒì„±)\n\n"
            "â‘¢ ë™ì‘ ë°©ì‹\n"
            "   - ê° í–‰ì˜ (ì¹´í…Œê³ ë¦¬ëª…/íŒë§¤í˜•íƒœ/ì›ë³¸ìƒí’ˆëª…)ì„ OpenAI APIë¡œ ë³´ë‚´ê³ ,\n"
            "     ê²°ê³¼ë¥¼ ST1_ì •ì œìƒí’ˆëª…ì— ì±„ìš´ ë’¤ '*_stage1_completed.xlsx'ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n"
            "   - 'ê¸°ì¡´ ê²°ê³¼ ë®ì–´ì“°ê¸°'ë¥¼ ë„ë©´ ì´ë¯¸ ì±„ì›Œì§„ í–‰ì€ ìë™ìœ¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤."
        )
        lbl_desc = tk.Label(root, text=desc, justify="left", anchor="w")
        lbl_desc.pack(fill=tk.X, padx=10, pady=(8, 4))

        # ----- ì„¤ì • ì˜ì—­ -----
        cfg_frame = tk.Frame(root)
        cfg_frame.pack(fill=tk.X, padx=10, pady=5)

        # API í‚¤
        tk.Label(cfg_frame, text="OpenAI API í‚¤:").grid(row=0, column=0, sticky="e", padx=5, pady=2)
        self.api_entry = tk.Entry(cfg_frame, width=55, show="*")
        self.api_entry.grid(row=0, column=1, columnspan=3, sticky="w", padx=5, pady=2)

        # ì €ì¥ëœ API í‚¤ ë¡œë“œ
        self.load_api_key()

        # ëª¨ë¸ ì„ íƒ  âœ… ê¸°ë³¸ê°’ gpt-5-nano
        tk.Label(cfg_frame, text="ëª¨ë¸:").grid(row=1, column=0, sticky="e", padx=5, pady=2)
        self.model_var = tk.StringVar(value="gpt-5-nano")
        self.cmb_model = ttk.Combobox(
            cfg_frame,
            textvariable=self.model_var,
            values=[
                "gpt-5-nano",   # GPT-5 nano
                "gpt-5-mini",   # ë¹ ë¥´ê³  ì €ë ´í•œ reasoning
                "gpt-5.1",      # ìµœê³  í’ˆì§ˆ reasoning
            ],
            width=15,
            state="readonly",
        )
        self.cmb_model.grid(row=1, column=1, sticky="w", padx=5, pady=2)

        lbl_model_hint = tk.Label(
            cfg_frame,
            text="gpt-5-nano: ì´ˆì €ë¹„ìš© / gpt-5-mini: ë¹ ë¥´ê³  ì €ë ´ / gpt-5.1: ìµœê³  í’ˆì§ˆ(ë¹„ìš©â†‘)",
            fg="#555",
            anchor="w",
        )
        lbl_model_hint.grid(row=1, column=2, columnspan=2, sticky="w", padx=5, pady=2)

        # temperature ìŠ¬ë¼ì´ë”
        tk.Label(cfg_frame, text="temperature:").grid(row=2, column=0, sticky="e", padx=5, pady=2)
        self.temp_var = tk.DoubleVar(value=0.2)
        self.temp_scale = tk.Scale(
            cfg_frame,
            variable=self.temp_var,
            from_=0.0,
            to=1.0,
            resolution=0.05,
            orient=tk.HORIZONTAL,
            length=200,
        )
        self.temp_scale.grid(row=2, column=1, sticky="w", padx=5, pady=2)

        lbl_temp_hint = tk.Label(
            cfg_frame,
            text="ë‚®ì„ìˆ˜ë¡ ê²°ì •ì , ë†’ì„ìˆ˜ë¡ ëœë¤ì„±â†‘ (gpt-5 ê³„ì—´ì—ì„œëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ë¬´ì‹œë  ìˆ˜ ìˆìŒ)",
            fg="#555",
            anchor="w",
        )
        lbl_temp_hint.grid(row=2, column=2, columnspan=2, sticky="w", padx=5, pady=2)

        # ì¤‘ê°„ ì €ì¥ ê°„ê²©
        tk.Label(cfg_frame, text="ì¤‘ê°„ ì €ì¥ ê°„ê²©(í–‰):").grid(row=3, column=0, sticky="e", padx=5, pady=2)
        self.save_every_var = tk.IntVar(value=10)
        self.spin_save_every = tk.Spinbox(
            cfg_frame,
            from_=1,
            to=1000,
            textvariable=self.save_every_var,
            width=6,
        )
        self.spin_save_every.grid(row=3, column=1, sticky="w", padx=5, pady=2)

        # ë®ì–´ì“°ê¸° ì—¬ë¶€
        self.overwrite_var = tk.BooleanVar(value=False)
        chk_overwrite = tk.Checkbutton(
            cfg_frame,
            text="ê¸°ì¡´ ST1_ì •ì œìƒí’ˆëª… ë®ì–´ì“°ê¸°",
            variable=self.overwrite_var,
        )
        chk_overwrite.grid(row=3, column=2, sticky="w", padx=5, pady=2)

        # ----- íŒŒì¼/ì‹¤í–‰ ë²„íŠ¼ ì˜ì—­ -----
        btn_frame = tk.Frame(root)
        btn_frame.pack(fill=tk.X, padx=10, pady=5)

        self.btn_select = tk.Button(
            btn_frame,
            text="Stage1 ë§µí•‘ ì—‘ì…€ ì„ íƒ",
            command=self.on_select_file,
        )
        self.btn_select.pack(side=tk.LEFT, padx=5)

        self.btn_run = tk.Button(
            btn_frame,
            text="ì‹¤í–‰",
            command=self.on_run_click,
        )
        self.btn_run.pack(side=tk.LEFT, padx=5)

        self.btn_stop = tk.Button(
            btn_frame,
            text="ì¤‘ë‹¨ ìš”ì²­",
            command=self.on_stop_click,
        )
        self.btn_stop.pack(side=tk.LEFT, padx=5)

        self.lbl_file = tk.Label(btn_frame, text="ì„ íƒëœ íŒŒì¼: (ì—†ìŒ)", anchor="w")
        self.lbl_file.pack(side=tk.LEFT, padx=10)

        # ----- ë¡œê·¸ ì˜ì—­ -----
        self.log_box = ScrolledText(root, wrap=tk.WORD, height=20)
        self.log_box.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)

    # ë¡œê·¸ ì¶œë ¥ (UI ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
    def _append_log(self, msg: str):
        self.log_box.insert(tk.END, msg + "\n")
        self.log_box.see(tk.END)

    def log(self, msg: str):
        self.root.after(0, self._append_log, msg)

    # API í‚¤ ì €ì¥/ë¡œë“œ
    def load_api_key(self):
        if os.path.exists(CONFIG_API_KEY_PATH):
            try:
                with open(CONFIG_API_KEY_PATH, "r", encoding="utf-8") as f:
                    key = f.read().strip()
                    if key:
                        self.api_entry.insert(0, key)
            except Exception:
                pass

    def save_api_key(self, api_key: str):
        api_key = api_key.strip()
        if not api_key:
            return
        try:
            with open(CONFIG_API_KEY_PATH, "w", encoding="utf-8") as f:
                f.write(api_key)
        except Exception as e:
            self.log(f"[WARN] API í‚¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    # íŒŒì¼ ì„ íƒ
    def on_select_file(self):
        filepath = filedialog.askopenfilename(
            title="Stage1 ë§µí•‘ ì—‘ì…€ íŒŒì¼ ì„ íƒ (*_stage1_mapping_api.xlsx)",
            filetypes=[("Excel files", "*.xlsx *.xls"), ("All files", "*.*")],
        )
        if not filepath:
            return

        base_name = os.path.basename(filepath)
        # íŒŒì¼ëª… ê²€ì‚¬: '_stage1_mapping' í¬í•¨ ì—¬ë¶€ (stage1_mapping_api ë„ í¬í•¨ë¨)
        if "_stage1_mapping" not in base_name:
            messagebox.showerror(
                "íŒŒì¼ ì´ë¦„ ì˜¤ë¥˜",
                "íŒŒì¼ ì´ë¦„ì— '_stage1_mapping' ì´ í¬í•¨ëœ Stage1 ë§µí•‘ íŒŒì¼ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            )
            return

        self.selected_file = filepath
        self.lbl_file.config(text=f"ì„ íƒëœ íŒŒì¼: {filepath}")

    # ì‹¤í–‰ ë²„íŠ¼
    def on_run_click(self):
        global STOP_REQUESTED

        api_key = self.api_entry.get().strip()
        if not api_key:
            messagebox.showerror("ì…ë ¥ ì˜¤ë¥˜", "OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            return

        if not self.selected_file:
            messagebox.showerror("ì…ë ¥ ì˜¤ë¥˜", "Stage1 ë§µí•‘ ì—‘ì…€ íŒŒì¼ì„ ë¨¼ì € ì„ íƒí•´ ì£¼ì„¸ìš”.")
            return

        # íŒŒì¼ëª… í•œ ë²ˆ ë” ê²€ì¦
        base_name = os.path.basename(self.selected_file)
        if "_stage1_mapping" not in base_name:
            messagebox.showerror(
                "íŒŒì¼ ì´ë¦„ ì˜¤ë¥˜",
                "íŒŒì¼ ì´ë¦„ì— '_stage1_mapping' ì´ í¬í•¨ëœ Stage1 ë§µí•‘ íŒŒì¼ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            )
            return

        model = self.model_var.get()
        temperature = float(self.temp_var.get())
        save_every = int(self.save_every_var.get())
        overwrite = bool(self.overwrite_var.get())

        # ì¤‘ë‹¨ í”Œë˜ê·¸ ì´ˆê¸°í™”
        STOP_REQUESTED = False

        # ì‹¤í–‰ ë²„íŠ¼ ì ê¸ˆ
        self.btn_run.config(state=tk.DISABLED)

        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ API ì‘ì—… ìˆ˜í–‰
        thread = threading.Thread(
            target=self.run_task,
            args=(api_key, self.selected_file, model, temperature, save_every, overwrite),
            daemon=True,
        )
        thread.start()

    # ì¤‘ë‹¨ ë²„íŠ¼
    def on_stop_click(self):
        global STOP_REQUESTED
        STOP_REQUESTED = True
        self.log("[INFO] ì¤‘ë‹¨ ìš”ì²­ í”Œë˜ê·¸ ì„¤ì •ë¨. í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ í–‰ ì´í›„ë¶€í„° ì¤‘ë‹¨ë©ë‹ˆë‹¤.")

    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
    def run_task(
        self,
        api_key: str,
        filepath: str,
        model: str,
        temperature: float,
        save_every: int,
        overwrite: bool,
    ):
        global client
        try:
            # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            client = OpenAI(api_key=api_key)

            # ì´ˆê¸°í™” ì„±ê³µ ì‹œ í‚¤ ì €ì¥
            self.save_api_key(api_key)

            self.log(f"[INFO] ì„ íƒëœ íŒŒì¼: {filepath}")
            self.log(f"[INFO] ì„ íƒ ëª¨ë¸: {model}")
            if model.startswith("gpt-5"):
                self.log("[INFO] temperature ì„¤ì •ê°’: %.2f (gpt-5 ê³„ì—´ì€ ë‚´ë¶€ì ìœ¼ë¡œ ë¬´ì‹œë  ìˆ˜ ìˆìŒ)" % temperature)
            else:
                self.log("[INFO] temperature ì„¤ì •ê°’: %.2f" % temperature)
            self.log(f"[INFO] ì¤‘ê°„ ì €ì¥ ê°„ê²©: {save_every}í–‰")
            self.log(f"[INFO] ê¸°ì¡´ ê²°ê³¼ ë®ì–´ì“°ê¸°: {overwrite}")

            out_path = run_stage1_on_excel(
                excel_path=filepath,
                model=model,
                temperature=temperature,
                max_output_tokens=DEFAULT_MAX_OUTPUT_TOKENS,
                save_every=save_every,
                overwrite=overwrite,
                log_func=self.log,
            )

            self.log("[INFO] ëª¨ë“  ì‘ì—… ì™„ë£Œ")
            self.root.after(
                0,
                lambda: messagebox.showinfo(
                    "ì™„ë£Œ",
                    f"Stage1 API ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n{out_path}",
                ),
            )
        except Exception as e:
            self.log("[FATAL] ì˜¤ë¥˜ ë°œìƒ:")
            self.log(str(e))
            self.root.after(
                0,
                lambda: messagebox.showerror("ì˜¤ë¥˜", f"ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n{e}"),
            )
        finally:
            self.root.after(0, lambda: self.btn_run.config(state=tk.NORMAL))


def main():
    root = tk.Tk()
    app = Stage1APIRunnerApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()
