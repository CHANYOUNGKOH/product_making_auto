# batch_stage1_core_Casche.py
"""
STAGE1 Batch API + ì—‘ì…€ ë³‘í•© í•µì‹¬ ë¡œì§ (ìºì‹± ìµœì í™” ë²„ì „)
- ğŸš€ í”„ë¡¬í”„íŠ¸ ìºì‹± ìµœì í™”: OpenAI Prompt Caching ê°€ì´ë“œì— ë§ê²Œ í”„ë¡¬í”„íŠ¸ êµ¬ì¡° ì¬êµ¬ì„±
  * ì •ì  ì½˜í…ì¸ (ì—­í• , ì œì•½, ê·œì¹™)ë¥¼ system í”„ë¡¬í”„íŠ¸ì— ë°°ì¹˜
  * ë™ì  ì½˜í…ì¸ (ì…ë ¥ ë°ì´í„°)ë¥¼ user í”„ë¡¬í”„íŠ¸ì— ë°°ì¹˜
  * í”„ë¡¬í”„íŠ¸ í”„ë¦¬í”½ìŠ¤ê°€ ëª¨ë“  ìš”ì²­ì—ì„œ ë™ì¼í•˜ë„ë¡ êµ¬ì„±
"""

import os
import json
import time
import threading
from typing import Any, Dict, List, Tuple, Optional

import pandas as pd
from openai import OpenAI

from prompts_stage1 import build_stage1_prompt, safe_str
from stage1_run_history import append_run_history

# =====================================
# í”„ë¡¬í”„íŠ¸ ìºì‹± ìµœì í™”: System/User ë¶„ë¦¬
# =====================================
# System í”„ë¡¬í”„íŠ¸ (ì™„ì „íˆ ì •ì , ëª¨ë“  ìš”ì²­ì—ì„œ ë™ì¼)
# âš ï¸ ì¤‘ìš”: í”„ë¡¬í”„íŠ¸ ìºì‹± í™œì„±í™”ë¥¼ ìœ„í•´ 1024 í† í° ì´ìƒì´ì–´ì•¼ í•¨
STAGE1_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ìœ„íƒíŒë§¤ìš© ìƒí’ˆëª… ì •ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì…ë ¥ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´‘ê³ ì™€ ë¸Œëœë“œ ê±°í’ˆì„ ì œê±°í•˜ê³ , ê²€ìƒ‰ì— ê°•í•œ ì •ë³´ ì¤‘ì‹¬ ìƒí’ˆëª… í•œ ì¤„ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
ìµœì¢… ì¶œë ¥ ì „ì— ì•„ë˜ ê·œì¹™ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ”ì§€ ìŠ¤ìŠ¤ë¡œ ì ê²€í•˜ë˜, ì ê²€ ê³¼ì •ì´ë‚˜ ì´ìœ ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

[í•µì‹¬ ì›ì¹™]
- ì›ë³¸ì— ëª…ì‹œëœ ì •ë³´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì¶”ì¸¡/ìœ ì¶”/ì¶”ë¡  ê¸ˆì§€)
- ë¸Œëœë“œ/ì‡¼í•‘ëª°ëª…/ê´‘ê³  ë¬¸êµ¬ ì œê±° í›„, ì˜ë¯¸ ìˆëŠ” ì •ë³´ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
- ê²°ê³¼ëŠ” "ëª…ì‚¬í˜• í‚¤ì›Œë“œ ë‚˜ì—´" í˜•íƒœì˜ ìƒí’ˆëª… í•œ ì¤„ì…ë‹ˆë‹¤.
- ë¼ë²¨/ì„¤ëª…/ë¬¸ì¥í˜• í‘œí˜„/ì´ëª¨í‹°ì½˜/ë¶ˆí•„ìš” ê¸°í˜¸ë¥¼ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë„ì–´ì“°ê¸° í¬í•¨ ìµœëŒ€ 60ì. ì´ˆê³¼ ì‹œ ëœ ì¤‘ìš”í•œ ìˆ˜ì‹ì–´ë¶€í„° ì œê±°í•©ë‹ˆë‹¤.

[ì •ì œ ê·œì¹™]

1. êµ¬ì¡° ì¬ë°°ì—´ (ìš°ì„ ìˆœìœ„)
- ê¶Œì¥ ìˆœì„œ: [í•µì‹¬ ì œí’ˆêµ°] > [ê¸°ëŠ¥/ì‚¬ìš©ìƒí™©] > [ê·œê²©/ìˆ˜ëŸ‰] > [ëŒ€ìƒ/ìŠ¤íƒ€ì¼] > [ì‹œì¦Œ/í…Œë§ˆ] > [ì˜µì…˜/ìƒ‰ìƒ]
- ë¬¸ì¥ì´ ì•„ë‹Œ ëª…ì‚¬í˜• í‚¤ì›Œë“œ ë‚˜ì—´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
- 60ì ì´ˆê³¼ ì‹œ ì¤‘ìš”ë„ê°€ ë‚®ì€ ìˆ˜ì‹ì–´ë¶€í„° ì œê±°í•˜ì—¬ 60ì ì´ë‚´ë¡œ ì¤„ì…ë‹ˆë‹¤.
- ì˜ˆì‹œ: "íŠ¹ê°€! ì¸ê¸° ì—¬ì„± ì½”íŠ¸ ê°€ì„ìš©" â†’ "ì—¬ì„± ê°€ì„ ì½”íŠ¸" (ê´‘ê³  ì œê±°, ìˆœì„œ ì •ë¦¬)

2. ë…¸ì´ì¦ˆ ë° ë¸Œëœë“œ ì œê±°
- ì‚­ì œ ëŒ€ìƒ(ì˜ˆì‹œ):
  Â· ê´‘ê³ Â·í™ë³´ ë¬¸êµ¬: ë¬´ë£Œë°°ì†¡, ë‹¹ì¼ë°°ì†¡, ì˜¤ëŠ˜ì¶œë°œ, íŠ¹ê°€, í–‰ì‚¬, ì¸ê¸°, ì¶”ì²œ, ìµœì €ê°€, ë¹…ì„¸ì¼,
    ì£¼ë¬¸í­ì£¼, ì¸ì‹¸í…œ, í•«ë”œ, MDì¶”ì²œ, í•œì •ìˆ˜ëŸ‰, êµ­ë¯¼í…œ, ì‹ ìƒí’ˆ, ë² ìŠ¤íŠ¸, í• ì¸, ì„¸ì¼, ì´ë²¤íŠ¸,
    ì¿ í°, ì‚¬ì€í’ˆ, ì¬ì…ê³ , ê°•ì¶”, ëŒ€ë°•, ì™„íŒ, í”„ë¦¬ë¯¸ì—„, ê³ í€„, ê°“ì„±ë¹„
  Â· ìƒì /ëª°/ë§ˆì¼“ëª…: â—‹â—‹ëª°, â—‹â—‹ìƒµ, â—‹â—‹ìŠ¤í† ì–´, â—‹â—‹ë§ˆì¼“, ê³µì‹ëª°, ì „ë¬¸ëª°, ì§ì˜ëª°,
    í”Œë˜ê·¸ì‹­ìŠ¤í† ì–´, ì˜¤í”„ë¼ì¸ë§¤ì¥, ì´íŒ, ë„ë§¤
  Â· ìœ„íƒíŒë§¤ìê°€ ê²½ìŸìš°ìœ„ë¥¼ ê°–ì§€ ëª»í•˜ëŠ” ëŒ€ì¤‘ ë¸Œëœë“œëª…: ë‚˜ì´í‚¤, ì•„ë””ë‹¤ìŠ¤, íœ ë¼, ë‰´ë°œë€ìŠ¤ ë“±
  Â· ì´ëª¨í‹°ì½˜Â·ê³¼í•œ ê¸°í˜¸: â™¥, â˜…, !!, ??, [], {}, /, Â·, |, ~ ë“± ì˜ë¯¸ ì—†ëŠ” ê¸°í˜¸
- ê´„í˜¸ëŠ” ê¼­ í•„ìš”í•œ ê·œê²©/ì˜µì…˜ í‘œê¸°ì—ë§Œ ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•˜ê³ ,
  ë¶ˆí•„ìš”í•œ ê´„í˜¸/ë¹ˆ ê´„í˜¸/ì¤‘ë³µ ê´„í˜¸ëŠ” ì œê±°í•©ë‹ˆë‹¤.
  ì˜ˆì‹œ: "ì˜ì(ì˜ì)" â†’ "ì˜ì"
- ìœ ì§€ ëŒ€ìƒ(ì†ì„±ì–´): í”¼ì¹˜ê¸°ëª¨, ì¿ ì…˜í¼, ìˆ˜ì œ, í•¸ë“œë©”ì´ë“œ, DIY, í˜¸í™˜ìš©, êµì²´ìš©, ë¦¬í•„ìš©,
  ë°©ìˆ˜, ë°©í’, ë°œìˆ˜, ë¯¸ë„ëŸ¼ë°©ì§€ ë“± "ì¬ì§ˆÂ·íŠ¹ì„±Â·ê¸°ëŠ¥"ì„ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´

3. ì •ë³´ ì •í™•ì„±(ì¶”ì¸¡ ê¸ˆì§€)
- ì›ë³¸ì— ì—†ëŠ” ì •ë³´(ì¬ì§ˆ, ê¸°ëŠ¥, ìš©ëŸ‰, ì¸ì¦, êµ¬ì„±, ë¸Œëœë“œ)ë¥¼ ìƒˆë¡œ ë§Œë“¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ìˆ«ì/ëª¨ë¸ëª…/ì‚¬ì´ì¦ˆ/ìš©ëŸ‰/ìˆ˜ëŸ‰ì€ ì›ë³¸ì— ë‚˜ì˜¨ ê°’ë§Œ ì‚¬ìš©í•˜ë©° ì„ì˜ë¡œ ë°”ê¾¸ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë¶ˆí•„ìš”í•œ ë°˜ë³µ/ì–´ìƒ‰í•œ í˜¼ìš©ì€ ì •ëˆí•˜ë˜ ì˜ë¯¸ëŠ” ë°”ê¾¸ì§€ ì•ŠìŠµë‹ˆë‹¤.
  ì˜ˆì‹œ: "í‹°ì…”ì¸  í‹°ì…”ì¸ " â†’ "í‹°ì…”ì¸ "
  ì˜ˆì‹œ: "T-shirt í‹°ì…”ì¸ " â†’ "í‹°ì…”ì¸ " (ì¤‘ë³µ ì œê±°)

4. ìˆ«ìÂ·ë‹¨ìœ„Â·ê¸°í˜¸ ì •ëˆ(ê°’ì€ ìœ ì§€)
- ë‹¨ìœ„/í‘œê¸°ëŠ” ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©° ê°„ê²°í•˜ê²Œ ì •ëˆí•©ë‹ˆë‹¤. (cm, mm, m, L, â„“, kg, g, ê°œ, ë§¤, ì¥, ì…, ì„¸íŠ¸ ë“±)
- ê³±ì…ˆ í‘œê¸°ëŠ” ê°€ëŠ¥í•œ í•œ "Ã—"ë¡œ í†µì¼í•©ë‹ˆë‹¤. (ì˜ˆ: 10x20 â†’ 10Ã—20)
- "1ê°œì…/1P/1PCS/1EA" ë“±ì€ ì˜ë¯¸ê°€ ê°™ìœ¼ë©´ "1ê°œ"ì²˜ëŸ¼ ê°„ë‹¨íˆ ì •ëˆí•©ë‹ˆë‹¤.
- ê¸°í˜¸/êµ¬ë¶„ì(, / | Â·)ëŠ” ê°€ëŠ¥í•˜ë©´ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.

5. ì˜µì…˜/ìƒ‰ìƒ ì²˜ë¦¬(ì›ë³¸ì— ìˆì„ ë•Œë§Œ)
- ì›ë³¸ ìƒí’ˆëª… ë˜ëŠ” ì…ë ¥ ì˜µì…˜ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì˜µì…˜/ìƒ‰ìƒë§Œ ë°˜ì˜í•©ë‹ˆë‹¤.
- ì˜µì…˜ì´ ê¸¸ë©´ "êµ¬ë¶„ì— ê°€ì¥ ì¤‘ìš”í•œ 1ê°œ ì˜µì…˜"ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ì œê±°í•©ë‹ˆë‹¤.
- ì›ë³¸ì— ì˜µì…˜/ìƒ‰ìƒì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

6. ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ìˆ˜ ê·œì¹™('ì›ë³¸ì— ëª…ì‹œëœ í•­ëª©ë§Œ' ì ìš©)
- íŒ¨ì…˜/ì˜ë¥˜: (ì›ë³¸ì— ìˆì„ ë•Œë§Œ) ìƒ‰ìƒ, ì‚¬ì´ì¦ˆ, ì†Œì¬ ìˆœì„œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜
- ì „ìì œí’ˆ: (ì›ë³¸ì— ìˆì„ ë•Œë§Œ) ëª¨ë¸ëª…, ìš©ëŸ‰, ìƒ‰ìƒ ìˆœì„œë¡œ ë°°ì¹˜
- ìƒí™œìš©í’ˆ: (ì›ë³¸ì— ìˆì„ ë•Œë§Œ) ìš©ëŸ‰/ìˆ˜ëŸ‰, ì¬ì§ˆ, ìš©ë„ ìˆœì„œë¡œ ë°°ì¹˜
â€» ì¹´í…Œê³ ë¦¬ë¡œ ì •ë³´ë¥¼ "ìœ ì¶”"í•˜ì—¬ ì¶”ê°€/ì‚­ì œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì›ë³¸ì— ìˆëŠ” í•­ëª©ë§Œ ì •ë ¬í•©ë‹ˆë‹¤.

7. ê¸¸ì´ ì œí•œ ì²˜ë¦¬(60ì ì´ˆê³¼ ì‹œ)
- ì•„ë˜ ìˆœì„œëŒ€ë¡œ ëœ ì¤‘ìš”í•œ ê²ƒë¶€í„° ì œê±°í•©ë‹ˆë‹¤.
  1) ê´‘ê³  ë¬¸êµ¬(ì´ë¯¸ ì œê±° ëŒ€ìƒ)
  2) ì¤‘ë³µ í‘œí˜„
  3) ì¤‘ìš”ë„ ë‚®ì€ ìˆ˜ì‹ì–´(ì˜ˆ: ê³ ê¸‰, í”„ë¦¬ë¯¸ì—„ ë“±)
  4) ë¶€ì°¨ì  ìŠ¤íƒ€ì¼/ëŒ€ìƒ ì •ë³´(ì›ë³¸ì— ìˆì–´ë„ ê¸¸ì´ ì´ˆê³¼ ì‹œ í›„ìˆœìœ„ë¡œ ì‚­ì œ)
  5) ì‹œì¦Œ/í…Œë§ˆ(í•„ìˆ˜ ì •ë³´ê°€ ì•„ë‹ˆë©´ ì‚­ì œ)
â€» ì‚­ì œ íŒë‹¨ì—ì„œë„ "ì¶”ì¸¡/ìœ ì¶”"ëŠ” í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

[ì¶œë ¥ í˜•ì‹]
- ì •ì œëœ ìƒí’ˆëª… í…ìŠ¤íŠ¸ **í•œ ì¤„ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
- ë¼ë²¨, ì„¤ëª…, ë¬¸ì¥í˜• í‘œí˜„, ì´ëª¨í‹°ì½˜ ì—†ì´ ìˆœìˆ˜í•œ ìƒí’ˆëª…ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.
- ì¤„ë°”ê¿ˆ ê¸ˆì§€.

[ìì²´ ì ê²€(ì¶œë ¥ ê¸ˆì§€)]
- ê´‘ê³ /ìƒì /ë¸Œëœë“œê°€ ë‚¨ì•„ ìˆì§€ ì•Šì€ê°€?
- ì›ë³¸ì— ì—†ëŠ” ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šì•˜ëŠ”ê°€?
- 60ì ì´ë‚´ì¸ê°€?
- í•œ ì¤„ë¡œ, ë¼ë²¨ ì—†ì´ ìƒí’ˆëª…ë§Œ ì¶œë ¥í–ˆëŠ”ê°€?

[ì •ì œ ì˜ˆì‹œ(í˜•ì‹ í•™ìŠµìš© / ì¶œë ¥ì€ ì˜ˆì‹œì²˜ëŸ¼ "í•œ ì¤„ ìƒí’ˆëª…ë§Œ")]
- ì›ë³¸: â˜…ë¬´ë£Œë°°ì†¡â˜… [ê³µì‹ëª°] í”„ë¦¬ë¯¸ì—„ ê²¨ìš¸ ê¸°ëª¨ ë ˆê¹…ìŠ¤ ì—¬ì„±ìš© 1+1 íŠ¹ê°€!!
  ê²°ê³¼: ê²¨ìš¸ ê¸°ëª¨ ë ˆê¹…ìŠ¤ ì—¬ì„±ìš© 1+1
- ì›ë³¸: (ë‹¹ì¼ì¶œê³ ) â—‹â—‹ìŠ¤í† ì–´ ìº í•‘ ëŒ€ìš©ëŸ‰ ì•„ì´ìŠ¤ë°•ìŠ¤ 25L ì¿¨ëŸ¬ ê°€ì„±ë¹„ ì¶”ì²œ
  ê²°ê³¼: ìº í•‘ ì•„ì´ìŠ¤ë°•ìŠ¤ 25L ì¿¨ëŸ¬
- ì›ë³¸: ë‚¨ì„± ë°˜íŒ” í‹°ì…”ì¸  ì—¬ë¦„ ì¸ê¸° ë² ìŠ¤íŠ¸ í• ì¸
  ê²°ê³¼: ë‚¨ì„± ë°˜íŒ” í‹°ì…”ì¸  ì—¬ë¦„
- ì›ë³¸: ë¸”ë™ M ë©´ í‹°ì…”ì¸  (ë¸Œëœë“œëª…) ì •í’ˆ
  ê²°ê³¼: ë©´ í‹°ì…”ì¸  ë¸”ë™ M
- ì›ë³¸: ì•„ì´í° 15 256GB ë¸”ë™ ì¼€ì´ìŠ¤ ì„¸íŠ¸ íŠ¹ê°€
  ê²°ê³¼: ì•„ì´í° 15 256GB ë¸”ë™ ì¼€ì´ìŠ¤ ì„¸íŠ¸
- ì›ë³¸: 1L ìœ ë¦¬ ë³´ì˜¨ë³‘ í…€ë¸”ëŸ¬ ì¶”ì²œ
  ê²°ê³¼: 1L ìœ ë¦¬ ë³´ì˜¨ë³‘ í…€ë¸”ëŸ¬
- ì›ë³¸: ë°˜ë ¤ë™ë¬¼ ê°•ì•„ì§€ ì‚°ì±… í•˜ë„¤ìŠ¤ ë¦¬ë“œì¤„ ì„¸íŠ¸ ì†Œí˜•ê²¬
  ê²°ê³¼: ê°•ì•„ì§€ ì‚°ì±… í•˜ë„¤ìŠ¤ ë¦¬ë“œì¤„ ì„¸íŠ¸ ì†Œí˜•ê²¬
- ì›ë³¸: ì°¨ëŸ‰ìš© ë²”ìš© ì—ì–´ì»¨ í•„í„° 2ê°œì… êµì²´ìš©
  ê²°ê³¼: ì°¨ëŸ‰ìš© ë²”ìš© ì—ì–´ì»¨ í•„í„° êµì²´ìš© 2ê°œ
- ì›ë³¸: ì£¼ë°© ì¼íšŒìš© ìœ„ìƒì¥ê°‘ 100ë§¤ ëŒ€ìš©ëŸ‰ íŠ¹ê°€
  ê²°ê³¼: ì¼íšŒìš© ìœ„ìƒì¥ê°‘ 100ë§¤
- ì›ë³¸: ìš•ì‹¤ ë¯¸ë„ëŸ¼ë°©ì§€ ë°œë§¤íŠ¸ ë…¼ìŠ¬ë¦½
  ê²°ê³¼: ìš•ì‹¤ ë¯¸ë„ëŸ¼ë°©ì§€ ë°œë§¤íŠ¸
- ì›ë³¸: ë‹¤ìš©ë„ ìˆ˜ë‚©í•¨ í”Œë¼ìŠ¤í‹± ì •ë¦¬ë°•ìŠ¤ ëŒ€í˜•
  ê²°ê³¼: í”Œë¼ìŠ¤í‹± ìˆ˜ë‚©í•¨ ì •ë¦¬ë°•ìŠ¤ ëŒ€í˜•
- ì›ë³¸: ë¬´ì„  ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í° ë…¸ì´ì¦ˆìº”ìŠ¬ë§
  ê²°ê³¼: ë¬´ì„  ë¸”ë£¨íˆ¬ìŠ¤ ì´ì–´í° ë…¸ì´ì¦ˆìº”ìŠ¬ë§
- ì›ë³¸: USB Cíƒ€ì… ê³ ì†ì¶©ì „ ì¼€ì´ë¸” 2m 2ê°œì…
  ê²°ê³¼: USB Cíƒ€ì… ê³ ì†ì¶©ì „ ì¼€ì´ë¸” 2m 2ê°œ
- ì›ë³¸: A4 í´ë¦¬ì–´íŒŒì¼ 20P ì„œë¥˜ì •ë¦¬
  ê²°ê³¼: A4 í´ë¦¬ì–´íŒŒì¼ 20P ì„œë¥˜ì •ë¦¬
- ì›ë³¸: ìº”ë“¤ì›Œë¨¸ ì „êµ¬í¬í•¨ ì„¸íŠ¸ ë¶ìœ ëŸ½ ê°ì„±
  ê²°ê³¼: ìº”ë“¤ì›Œë¨¸ ì „êµ¬í¬í•¨ ì„¸íŠ¸
- ì›ë³¸: ìˆ˜ì œ DIY ë¹„ì¦ˆ íŒ”ì°Œ ë§Œë“¤ê¸° í‚¤íŠ¸
  ê²°ê³¼: DIY ë¹„ì¦ˆ íŒ”ì°Œ ë§Œë“¤ê¸° í‚¤íŠ¸
- ì›ë³¸: ì—¬ë¦„ ëƒ‰ê° ì´ë¶ˆ ì‹±ê¸€ 150Ã—200cm
  ê²°ê³¼: ì—¬ë¦„ ëƒ‰ê° ì´ë¶ˆ ì‹±ê¸€ 150Ã—200cm
- ì›ë³¸: ê²¨ìš¸ ë°©í’ ê¸°ëª¨ ì¥ê°‘ ë‚¨ì„±ìš©
  ê²°ê³¼: ê²¨ìš¸ ë°©í’ ê¸°ëª¨ ì¥ê°‘ ë‚¨ì„±ìš©
- ì›ë³¸: ì–´ë¦°ì´ ë¯¸ìˆ  ë¬¼ê° 12ìƒ‰ ì„¸íŠ¸
  ê²°ê³¼: ì–´ë¦°ì´ ë¯¸ìˆ  ë¬¼ê° 12ìƒ‰ ì„¸íŠ¸
- ì›ë³¸: ê³ ì–‘ì´ ìŠ¤í¬ë˜ì²˜ ê³¨íŒì§€ ë¦¬í•„ 3ê°œì…
  ê²°ê³¼: ê³ ì–‘ì´ ìŠ¤í¬ë˜ì²˜ ê³¨íŒì§€ ë¦¬í•„ 3ê°œ
- ì›ë³¸: ìº í•‘ ì ‘ì´ì‹ ì˜ì ê²½ëŸ‰ íœ´ëŒ€ìš©
  ê²°ê³¼: ìº í•‘ ì ‘ì´ì‹ ì˜ì ê²½ëŸ‰ íœ´ëŒ€ìš©

ìœ„ ê·œì¹™ì„ ì—„ìˆ˜í•˜ì—¬, ì •ì œëœ ìƒí’ˆëª… í…ìŠ¤íŠ¸ **í•œ ì¤„ë§Œ** ì¶œë ¥í•˜ì‹­ì‹œì˜¤."""

# User í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë™ì  ë°ì´í„°ë§Œ í¬í•¨)
STAGE1_USER_PROMPT_TEMPLATE = """[ì…ë ¥ ì •ë³´]
- ì¹´í…Œê³ ë¦¬ëª…: {category}
- íŒë§¤í˜•íƒœ: {sale_type}  (ì°¸ê³ ìš© ë©”íƒ€ ì •ë³´ì´ë©°, ê²°ê³¼ ìƒí’ˆëª…ì— ê·¸ëŒ€ë¡œ ì“°ì§€ ë§ ê²ƒ)
- ì›ë³¸ ìƒí’ˆëª…: {raw_name}"""

def fmt_safe(v: Any) -> str:
    """
    str(v)ë¥¼ í•œ ë²ˆ ê°ì‹¼ ë’¤, .format()ì— ì•ˆì „í•˜ê²Œ ë„£ê¸° ìœ„í•œ ì´ìŠ¤ì¼€ì´í”„.
    - { â†’ {{, } â†’ }}
    """
    s = safe_str(v)
    return s.replace("{", "{{").replace("}", "}}")

# API í‚¤ íŒŒì¼ ê²½ë¡œ (GUIì™€ ê³µìœ )
API_KEY_FILE = ".openai_api_key_batch"

# =======================
# ì‹œê°„/íƒ€ì„ì¡´ ìœ í‹¸
# =======================
try:
    from zoneinfo import ZoneInfo  # Python 3.9+
except ImportError:  # pragma: no cover
    ZoneInfo = None  # type: ignore


def get_seoul_now():
    """
    Asia/Seoul ê¸°ì¤€ í˜„ì¬ ì‹œê°ì„ datetimeìœ¼ë¡œ ë°˜í™˜.
    zoneinfo ê°€ ì—†ìœ¼ë©´ naive datetime ìœ¼ë¡œ fallback.
    """
    from datetime import datetime, timezone, timedelta

    if ZoneInfo is not None:
        return datetime.now(ZoneInfo("Asia/Seoul"))
    # fallback: UTC+9 ê³ ì •
    return datetime.now(timezone(timedelta(hours=9)))


# =======================
# API í‚¤ ë¡œë“œ/ì €ì¥
# =======================

def load_api_key_from_file() -> str:
    if os.path.exists(API_KEY_FILE):
        try:
            with open(API_KEY_FILE, "r", encoding="utf-8") as f:
                return f.read().strip()
        except Exception:
            return ""
    return ""


def save_api_key_to_file(key: str) -> None:
    try:
        with open(API_KEY_FILE, "w", encoding="utf-8") as f:
            f.write(key.strip())
    except Exception as e:
        print(f"[WARN] API í‚¤ ì €ì¥ ì‹¤íŒ¨: {e}")


# =======================
# í† í° ë‹¨ê°€ & ë¹„ìš© ê³„ì‚° (ST1 ì „ìš©)
# =======================

# ëª¨ë¸ë³„ 100ë§Œ í† í°ë‹¹ ë‹¨ê°€ (USD) - ST1 ëŸ¬ë„ˆì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤
MODEL_PRICING: Dict[str, Dict[str, float]] = {
    # ì°¸ê³ : ì‹¤ì œ ê°€ê²©ì€ OpenAI ê³µì‹ ë¬¸ì„œ ê¸°ì¤€ìœ¼ë¡œ í•„ìš” ì‹œ ìˆ˜ì •
    "gpt-5": {
        "input_per_million": 1.250,
        "cached_input_per_million": 0.125,
        "output_per_million": 10.000,
    },
    "gpt-5-mini": {
        "input_per_million": 0.250,
        "cached_input_per_million": 0.025,
        "output_per_million": 1.250,
    },
    "gpt-5-nano": {
        "input_per_million": 0.050,
        "cached_input_per_million": 0.005,
        "output_per_million": 0.300,
    },
}


def compute_cost_usd(
    model_name: str,
    total_input_tokens: int,
    total_output_tokens: int,
) -> Optional[Dict[str, float]]:
    """
    ëª¨ë¸ë³„ í† í° ë‹¨ê°€ë¥¼ ì´ìš©í•´ ëŒ€ëµì ì¸ ë¹„ìš©(USD) ê³„ì‚°.
    - ìºì‹œ ì…ë ¥ í† í°ì€ ì•„ì§ êµ¬ë¶„í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¼ë°˜ ì…ë ¥ ë‹¨ê°€ë§Œ ì‚¬ìš©.
    - ëª¨ë¸ ì •ë³´ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜.
    """
    pricing = MODEL_PRICING.get(model_name)
    if not pricing:
        return None

    in_million = total_input_tokens / 1_000_000.0
    out_million = total_output_tokens / 1_000_000.0

    input_cost = in_million * pricing["input_per_million"]
    output_cost = out_million * pricing["output_per_million"]
    total_cost = input_cost + output_cost

    return {
        "input_cost": input_cost,
        "output_cost": output_cost,
        "total_cost": total_cost,
    }


# =====================================
# ì‘ë‹µ í…ìŠ¤íŠ¸ / ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
# =====================================

def extract_text_from_response_dict(resp: Dict[str, Any]) -> str:
    """
    Batch ê²°ê³¼ JSONL ì•ˆì˜ 'response' ë”•ì…”ë„ˆë¦¬ì—ì„œ
    ì‚¬ëŒì´ ì½ì„ í…ìŠ¤íŠ¸ë§Œ ë½‘ì•„ë‚´ëŠ” í•¨ìˆ˜.

    âš ï¸ ì£¼ì˜:
    Batch APIì—ì„œëŠ” í•œ ì¤„ì´ ì´ëŸ° í˜•íƒœë‹¤.
      {
        "custom_id": "row-0",
        "response": {
          "status_code": 200,
          "request_id": "res_xxx",
          "body": { ...responses.create ê²°ê³¼... }
        },
        "error": null
      }

    ê·¸ë˜ì„œ ë¨¼ì € resp["body"] ë¥¼ êº¼ë‚´ì„œ ê·¸ ì•ˆì—ì„œ output ì„ ì°¾ì•„ì•¼ í•œë‹¤.
    """
    try:
        # 1) Batch ì‘ë‹µ envelope í’€ê¸° (status_code / body êµ¬ì¡°)
        body = resp.get("body") if isinstance(resp, dict) and "body" in resp else resp

        chunks: List[str] = []

        # 2) Responses API í‘œì¤€ êµ¬ì¡°: body["output"][..]["content"][..]["text"]
        output_list = body.get("output") or []
        for out in output_list:
            o_type = out.get("type")
            # type ì´ ë”°ë¡œ ì•ˆ ë¶™ê±°ë‚˜ "message" ì¸ ê²½ìš°ë§Œ ì‚¬ìš©
            if o_type not in (None, "message"):
                continue

            content_list = out.get("content") or []
            for c in content_list:
                t_obj = c.get("text")
                if isinstance(t_obj, str):
                    # text ê°€ ê·¸ëƒ¥ ë¬¸ìì—´ì¼ ë•Œ
                    chunks.append(t_obj)
                elif isinstance(t_obj, dict):
                    # {"value": "..."} í˜•íƒœì¼ ë•Œ
                    val = t_obj.get("value")
                    if isinstance(val, str):
                        chunks.append(val)

        if chunks:
            full_text = "\n".join(chunks).strip()
            # ìš°ë¦¬ëŠ” "ì •ì œëœ ìƒí’ˆëª… í•œ ì¤„"ë§Œ í•„ìš”í•˜ë‹ˆê¹Œ ì²« ì¤„ë§Œ ì‚¬ìš©
            first_line = full_text.splitlines()[0].strip()
            return first_line

    except Exception:
        # ì—¬ê¸°ì„œ ì—ëŸ¬ ë‚˜ë”ë¼ë„ ì•„ë˜ fallback ìœ¼ë¡œ ë„˜ì–´ê°€ë„ë¡ ì¡°ìš©íˆ ë¬´ì‹œ
        pass

    # 3) í˜¹ì‹œ body ì— output_text í•„ë“œë§Œ ìˆëŠ” ê²½ìš° (ë¯¸ë˜ í˜¸í™˜ìš©)
    maybe = resp.get("output_text") if isinstance(resp, dict) else None
    if isinstance(maybe, str) and maybe.strip():
        return maybe.strip()

    return ""


def extract_usage_from_response_dict(resp: Dict[str, Any]) -> Tuple[int, int, int]:
    """
    Batch ê²°ê³¼ JSONL ì•ˆì˜ 'response' ë”•ì…”ë„ˆë¦¬ì—ì„œ
    í† í° ì‚¬ìš©ëŸ‰ (input, output, reasoning)ì„ ì¶”ì¶œ.
    """
    try:
        body = resp.get("body") if isinstance(resp, dict) and "body" in resp else resp
        usage = body.get("usage") or {}
        in_tok = int(usage.get("input_tokens") or 0)
        out_tok = int(usage.get("output_tokens") or 0)

        reasoning_tok = 0
        details = usage.get("output_tokens_details") or {}
        if isinstance(details, dict):
            reasoning_tok = int(details.get("reasoning_tokens") or 0)

        return in_tok, out_tok, reasoning_tok
    except Exception:
        return 0, 0, 0


# =====================================
# Batch API í•µì‹¬ ë¡œì§
# =====================================

def create_batch_input_jsonl(
    excel_path: str,
    jsonl_path: str,
    model_name: str = "gpt-5-mini",
    reasoning_effort: str = "low",
):
    """
    ì—‘ì…€ íŒŒì¼(ì›ë³¸ìƒí’ˆëª…, ì¹´í…Œê³ ë¦¬ëª…, íŒë§¤í˜•íƒœ) â†’ Batch APIìš© JSONL ìƒì„±.
    - ì¹´í…Œê³ ë¦¬ëª… / íŒë§¤í˜•íƒœ / ì›ë³¸ìƒí’ˆëª… ì¤‘ í•˜ë‚˜ë¼ë„ ë¹„ì–´ ìˆìœ¼ë©´ ê·¸ í–‰ì€ JSONLì—ì„œ ì œì™¸.
    - ì œì™¸ëœ í–‰ì€ ë³„ë„ ì—‘ì…€ íŒŒì¼(<ì›ë³¸ëª…>_stage1_skipped_rows.xlsx)ì— ì €ì¥.
    - ë°˜í™˜ê°’(info_dict)ìœ¼ë¡œ ì „ì²´/ë³€í™˜/ì œì™¸ ê°œìˆ˜ì™€ ì œì™¸íŒŒì¼ ê²½ë¡œë¥¼ ëŒë ¤ì¤Œ.
    """
    df = pd.read_excel(excel_path)

    required_cols = ["ì›ë³¸ìƒí’ˆëª…", "ì¹´í…Œê³ ë¦¬ëª…", "íŒë§¤í˜•íƒœ"]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"ì—‘ì…€ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {col}")

    total_rows = len(df)
    written_count = 0
    skipped_rows: List[Dict[str, Any]] = []

    with open(jsonl_path, "w", encoding="utf-8") as f:
        for idx, row in df.iterrows():
            raw_name = safe_str(row["ì›ë³¸ìƒí’ˆëª…"])
            category = safe_str(row["ì¹´í…Œê³ ë¦¬ëª…"])
            sale_type = safe_str(row["íŒë§¤í˜•íƒœ"])

            missing_fields = []
            if not category:
                missing_fields.append("ì¹´í…Œê³ ë¦¬ëª…")
            if not sale_type:
                missing_fields.append("íŒë§¤í˜•íƒœ")
            if not raw_name:
                missing_fields.append("ì›ë³¸ìƒí’ˆëª…")

            # í•˜ë‚˜ë¼ë„ ë¹„ì–´ ìˆìœ¼ë©´ JSONLì—ëŠ” ì•ˆ ì“°ê³ , ìŠ¤í‚µ ëª©ë¡ì—ë§Œ ì €ì¥
            if missing_fields:
                skipped_rows.append({
                    "ì—‘ì…€_ì¸ë±ìŠ¤": idx,
                    "ëˆ„ë½í•­ëª©": ", ".join(missing_fields),
                    "ì¹´í…Œê³ ë¦¬ëª…": category,
                    "íŒë§¤í˜•íƒœ": sale_type,
                    "ì›ë³¸ìƒí’ˆëª…": raw_name,
                })
                continue

            # í”„ë¡¬í”„íŠ¸ ìºì‹± ìµœì í™”: system/user ë¶„ë¦¬
            system_content = [{"type": "input_text", "text": STAGE1_SYSTEM_PROMPT}]
            user_prompt = STAGE1_USER_PROMPT_TEMPLATE.format(
                category=fmt_safe(category),
                sale_type=fmt_safe(sale_type),
                raw_name=fmt_safe(raw_name)
            )
            user_content = [{"type": "input_text", "text": user_prompt}]

            body: Dict[str, Any] = {
                "model": model_name,
                "input": [
                    {
                        "role": "system",
                        "content": system_content,
                    },
                    {
                        "role": "user",
                        "content": user_content,
                    }
                ],
                "reasoning": {"effort": reasoning_effort},
                # í”„ë¡¬í”„íŠ¸ ìºì‹± ìµœì í™”
                "prompt_cache_key": "stage1_v1",  # ë²„í‚· ë¶„ì‚°ì€ GUIì—ì„œ ì²˜ë¦¬
                # prompt_cache_retentionì€ ëª¨ë¸ì´ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±°
                # (prompt_cache_keyë§Œìœ¼ë¡œë„ í”„ë¡¬í”„íŠ¸ ìºì‹±ì´ ì‘ë™í•  ìˆ˜ ìˆìŒ)
            }

            item = {
                "custom_id": f"row-{idx}",
                "method": "POST",
                "url": "/v1/responses",
                "body": body,
            }

            f.write(json.dumps(item, ensure_ascii=False) + "\n")
            written_count += 1

    # ìŠ¤í‚µëœ í–‰ ìš”ì•½ ì—‘ì…€ ì €ì¥
    skipped_path = ""
    if skipped_rows:
        base_dir = os.path.dirname(excel_path)
        base_name = os.path.splitext(os.path.basename(excel_path))[0]
        skipped_path = os.path.join(base_dir, f"{base_name}_stage1_skipped_rows.xlsx")
        skipped_df = pd.DataFrame(skipped_rows)
        skipped_df.to_excel(skipped_path, index=False)

    # ê°„ë‹¨ ìš”ì•½ ë°˜í™˜
    info = {
        "total_rows": total_rows,
        "written_count": written_count,
        "skipped_count": len(skipped_rows),
        "skipped_path": skipped_path,
    }
    return info


def submit_batch(jsonl_path: str, client: OpenAI, completion_window: str = "24h") -> str:
    """
    JSONL íŒŒì¼ ì—…ë¡œë“œ í›„ Batch ìƒì„±, batch_id ë°˜í™˜
    """
    with open(jsonl_path, "rb") as f:
        file_obj = client.files.create(
            file=f,
            purpose="batch",
        )

    batch = client.batches.create(
        input_file_id=file_obj.id,
        endpoint="/v1/responses",
        completion_window=completion_window,
    )
    return batch.id


def wait_and_collect_batch(
    batch_id: str,
    excel_path: str,
    output_excel_path: str,
    client: OpenAI,
    poll_interval_sec: int = 30,
    log_fn=None,
    stop_event: Optional[threading.Event] = None,
    model_name: Optional[str] = None,
    reasoning_effort: Optional[str] = None,
) -> None:
    """
    - batch_id ìƒíƒœë¥¼ í´ë§í•´ì„œ completed ë˜ë©´
    - output JSONLì„ ë‹¤ìš´ë¡œë“œí•˜ê³ 
    - custom_id(row-0, row-1, ...) ê¸°ì¤€ìœ¼ë¡œ ST1_ê²°ê³¼ìƒí’ˆëª… ì»¬ëŸ¼ì— ë³‘í•©
    - stop_event ê°€ set ë˜ë©´ ìˆ˜ì§‘ ì¤‘ë‹¨
    - ìˆ˜ì§‘ì´ ì •ìƒ ì™„ë£Œë˜ë©´ stage1_run_history ì— í† í°/ë¹„ìš© ë¡œê·¸ ë‚¨ê¹€
    """
    def log(msg: str):
        if log_fn:
            log_fn(msg)
        else:
            print(msg)

    def check_stop():
        if stop_event is not None and stop_event.is_set():
            log("[COLLECT] ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ìˆ˜ì§‘ ì¤‘ë‹¨.")
            raise RuntimeError("ì‚¬ìš©ìê°€ ê²°ê³¼ ìˆ˜ì§‘ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")

    start_dt = get_seoul_now()
    start_time = time.time()

    log(f"[COLLECT] batch_id={batch_id} ìƒíƒœ ì¡°íšŒ ì‹œì‘...")

    # 1) Batch ìƒíƒœ í´ë§
    while True:
        check_stop()

        batch = client.batches.retrieve(batch_id)
        log(f"  - status={batch.status}, request_counts={getattr(batch, 'request_counts', None)}")
        if batch.status in ("completed", "failed", "cancelled", "expired"):
            break

        # poll_interval_sec ë™ì•ˆ 1ì´ˆ ë‹¨ìœ„ë¡œ ëŠì–´ì„œ ì¤‘ë‹¨ ì—¬ë¶€ ì²´í¬
        for _ in range(poll_interval_sec):
            check_stop()
            time.sleep(1)

    check_stop()

    if batch.status != "completed":
        raise RuntimeError(f"ë°°ì¹˜ê°€ ì™„ë£Œ ìƒíƒœê°€ ì•„ë‹™ë‹ˆë‹¤: status={batch.status}")

    output_file_id = getattr(batch, "output_file_id", None)
    if not output_file_id:
        # ì‹ ë²„ì „ì—ì„œ output_file_ids ë°°ì—´ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ë³´ì¡° ì²˜ë¦¬
        output_ids = getattr(batch, "output_file_ids", None)
        if output_ids and isinstance(output_ids, (list, tuple)) and len(output_ids) > 0:
            output_file_id = output_ids[0]

    if not output_file_id:
        raise RuntimeError("batch.output_file_id ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    log(f"[COLLECT] output_file_id={output_file_id} ë‹¤ìš´ë¡œë“œ ì¤‘...")
    file_content = client.files.content(output_file_id)

    if hasattr(file_content, "read"):
        data_bytes = file_content.read()
    elif hasattr(file_content, "iter_bytes"):
        # ì¼ë¶€ í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ì—ì„œëŠ” iter_bytes() ë¡œ chunk ê°€ ì˜¬ ìˆ˜ ìˆìŒ
        chunks = []
        for ch in file_content.iter_bytes():
            chunks.append(ch)
        data_bytes = b"".join(chunks)
    else:
        data_bytes = file_content  # type: ignore

    text = data_bytes.decode("utf-8")
    lines = [ln for ln in text.splitlines() if ln.strip()]

    # 2) JSONL í•œ ì¤„ì”© íŒŒì‹± â†’ ê²°ê³¼/í† í° ì§‘ê³„
    result_map: Dict[str, str] = {}
    total_in_tok = 0
    total_out_tok = 0
    total_reasoning_tok = 0
    api_rows = 0

    for ln in lines:
        obj = json.loads(ln)
        custom_id = obj.get("custom_id")
        resp = obj.get("response")
        error = obj.get("error")

        if error is not None:
            log(f"[ERROR] custom_id={custom_id} ì—ëŸ¬ ë°œìƒ: {error}")
            continue
        if not resp:
            continue

        refined = extract_text_from_response_dict(resp)
        result_map[custom_id] = refined

        in_tok, out_tok, reasoning_tok = extract_usage_from_response_dict(resp)
        total_in_tok += in_tok
        total_out_tok += out_tok
        total_reasoning_tok += reasoning_tok
        api_rows += 1

    log(f"[COLLECT] ê²°ê³¼ ë§¤í•‘ ê°œìˆ˜: {len(result_map)}")
    log(
        f"[USAGE] API í˜¸ì¶œ ìˆ˜(api_rows)={api_rows}, "
        f"input_tokens={total_in_tok}, output_tokens={total_out_tok}, "
        f"reasoning_tokens={total_reasoning_tok}"
    )

    # 3) ì—‘ì…€ ë³‘í•©
    df = pd.read_excel(excel_path)
    total_rows = len(df)

    if "ST1_ê²°ê³¼ìƒí’ˆëª…" not in df.columns:
        df["ST1_ê²°ê³¼ìƒí’ˆëª…"] = ""
    if "ST1_íŒë§¤í˜•íƒœ" not in df.columns:
        df["ST1_íŒë§¤í˜•íƒœ"] = ""

    for idx in range(len(df)):
        cid = f"row-{idx}"
        if cid in result_map:
            df.at[idx, "ST1_ê²°ê³¼ìƒí’ˆëª…"] = result_map[cid]
            df.at[idx, "ST1_íŒë§¤í˜•íƒœ"] = safe_str(df.at[idx, "íŒë§¤í˜•íƒœ"])

    df.to_excel(output_excel_path, index=False)
    log(f"[COLLECT] ì—‘ì…€ ë³‘í•© ì™„ë£Œ: {output_excel_path}")

    # 4) ë¹„ìš© ê³„ì‚° + ëŸ¬ë‹ íƒ€ì„/íˆìŠ¤í† ë¦¬ ê¸°ë¡
    elapsed_seconds = time.time() - start_time
    finish_dt = get_seoul_now()

    input_cost_usd = None
    output_cost_usd = None
    total_cost_usd = None

    if model_name:
        cost_info = compute_cost_usd(model_name, total_in_tok, total_out_tok)
        if cost_info:
            input_cost_usd = cost_info["input_cost"]
            output_cost_usd = cost_info["output_cost"]
            total_cost_usd = cost_info["total_cost"]
            log(
                f"[COST] model={model_name}, "
                f"input=${input_cost_usd:.6f}, output=${output_cost_usd:.6f}, "
                f"total=${total_cost_usd:.6f}"
            )

    # stage1_run_history.xlsx ì— í•œ ì¤„ ì¶”ê°€ (ST1-BATCH)
    try:
        append_run_history(
            stage="ST1-BATCH",
            model_name=model_name or "(unknown)",
            reasoning_effort=reasoning_effort or "(unknown)",
            src_file=excel_path,
            total_rows=total_rows,
            api_rows=api_rows,
            elapsed_seconds=elapsed_seconds,
            total_in_tok=total_in_tok,
            total_out_tok=total_out_tok,
            total_reasoning_tok=total_reasoning_tok,
            input_cost_usd=input_cost_usd,
            output_cost_usd=output_cost_usd,
            total_cost_usd=total_cost_usd,
            start_dt=start_dt,
            finish_dt=finish_dt,
        )
        log("[INFO] stage1_run_history.xlsx ì— ST1-BATCH ì‹¤í–‰ ê¸°ë¡ ì¶”ê°€ ì™„ë£Œ.")
    except Exception as e:
        log(f"[WARN] ì‹¤í–‰ ì´ë ¥ ê¸°ë¡(stage1_run_history) ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
